{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "\n",
    "import os, pickle, time, re, sys, operator\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.metrics import auc, classification_report, roc_auc_score, f1_score, matthews_corrcoef, balanced_accuracy_score, r2_score , confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from my_util import *\n",
    "from lime.lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# from pyexplainer.pyexplainer_pyexplainer import PyExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from pyexplainer.pyexplainer_pyexplainer import PyExplainer\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "data_path = './dataset/'\n",
    "result_dir = './new_eval_result/'\n",
    "dump_dataframe_dir = './dump_df/'\n",
    "pyExp_dir = './pyExplainer_obj/'\n",
    "other_object_dir = './other_object/'\n",
    "# proj_name = 'qt' # ['openstack','qt']\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "# def test_lime(proj_name):\n",
    "#     global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name)\n",
    "#     all_eval_result = pd.DataFrame()\n",
    "    \n",
    "#     for i in range(0,len(feature_df)):\n",
    "#         X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "#         row_index = str(X_explain.index[0])\n",
    "\n",
    "#         py_exp = pickle.load(open(pyExp_dir+proj_name+'_rulefit_crossoverinterpolation_'+row_index+'.pkl','rb'))\n",
    "#         lime_exp = pickle.load(open(pyExp_dir+proj_name+'_lime_'+row_index+'.pkl','rb'))\n",
    "\n",
    "#         # this data can be used for both local and global model\n",
    "#         py_exp_synthetic_data = py_exp['synthetic_data'].values\n",
    "#         # this data can be used with global model only\n",
    "#         lime_exp_synthetic_data = lime_exp['synthetic_instance_for_global_model']\n",
    "#         # this data can be used with local model only\n",
    "#         lime_exp_synthetic_data_local = lime_exp['synthetic_instance_for_lobal_model']\n",
    "        \n",
    "#         display(X_explain)\n",
    "#         display(lime_exp_synthetic_data[:5,:])\n",
    "#         display(lime_exp_synthetic_data_local[:5,:])\n",
    "        \n",
    "#         break\n",
    "        \n",
    "# test_lime('openstack')\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "flip_sign_dict = {\n",
    "    '<': '>=',\n",
    "    '>': '<=',\n",
    "    '=': '!=',\n",
    "    '>=': '<',\n",
    "    '<=': '>',\n",
    "    '!=': '=='\n",
    "}\n",
    "\n",
    "'''\n",
    "    input: rule (str)\n",
    "'''\n",
    "def flip_rule(rule):\n",
    "    rule = re.sub(r'\\b=\\b',' = ',rule) # for LIME\n",
    "#     rule = rule.replace('&','and') # for RuleFit\n",
    "    found_rule = re.findall('.* <=? [a-zA-Z]+ <=? .*', rule) # for LIME\n",
    "    ret = ''\n",
    "    \n",
    "    # for LIME that has condition like this: 0.53 < nref <= 0.83\n",
    "    if len(found_rule) > 0:\n",
    "        found_rule = found_rule[0]\n",
    "    \n",
    "        var_in_rule = re.findall('[a-zA-Z]+',found_rule)\n",
    "\n",
    "        var_in_rule = var_in_rule[0]\n",
    "        \n",
    "        splitted_rule = found_rule.split(var_in_rule)\n",
    "        splitted_rule[0] = splitted_rule[0] + var_in_rule # for left side\n",
    "        splitted_rule[1] = var_in_rule + splitted_rule[1] # for right side\n",
    "        combined_rule = splitted_rule[0] + ' or ' + splitted_rule[1]\n",
    "        ret = flip_rule(combined_rule)\n",
    "        \n",
    "    else:\n",
    "        for tok in rule.split():\n",
    "            if tok in flip_sign_dict:\n",
    "                ret = ret + flip_sign_dict[tok] + ' '\n",
    "            else:\n",
    "                ret = ret + tok + ' '\n",
    "    return ret\n",
    "\n",
    "def get_top_k_global_features(global_model, indep, top_k_global_feature_num = 5):\n",
    "    global_feature_df = pd.DataFrame()\n",
    "    global_feature_df['feature'] = indep\n",
    "    global_feature_df['importance'] = global_model.feature_importances_\n",
    "\n",
    "    global_feature_df = global_feature_df.sort_values(by='importance',ascending=False)\n",
    "\n",
    "    top_k_global_features = list(global_feature_df['feature'])[:top_k_global_feature_num]\n",
    "\n",
    "    return top_k_global_features\n",
    "    \n",
    "def sort_global_feature(global_model, indep):\n",
    "    global_feature_df = pd.DataFrame()\n",
    "    global_feature_df['feature'] = indep\n",
    "    global_feature_df['importance'] = global_model.feature_importances_\n",
    "\n",
    "    global_feature_df = global_feature_df.sort_values(by='importance',ascending=False)\n",
    "\n",
    "    sorted_global_features = list(global_feature_df['feature'])\n",
    "\n",
    "    return sorted_global_features\n",
    "\n",
    "def get_rule_str_of_rulefit(local_rulefit_model):\n",
    "    rule_df = local_rulefit_model.get_rules()\n",
    "#     print(rule_df)\n",
    "    top_k = 5\n",
    "    top_k_positive_rules = rule_df[(rule_df.coef > 0) & (rule_df.type=='rule')].sort_values(\"importance\", ascending=False).head(top_k)\n",
    "#     top_k_positive_rules = rule_df[(rule_df.coef > 0) & (rule_df.type=='rule')].sort_values(\"coef\", ascending=False).head(top_k)\n",
    "\n",
    "    the_best_defective_rule_str = list(top_k_positive_rules['rule'])[0]\n",
    "    \n",
    "    return the_best_defective_rule_str\n",
    "\n",
    "def get_rule_str_of_rulefit_new_version(local_rulefit_model):\n",
    "    rule_df = local_rulefit_model.get_rules()\n",
    "    rule_df =  rule_df[(rule_df.coef > 0) & (rule_df.type=='rule')].sort_values(\"importance\", ascending=False)\n",
    "    \n",
    "    rule_list = list(rule_df['rule'])\n",
    "    dup_feature_in_rule = [] # true or false...\n",
    "    \n",
    "    for r in rule_list:\n",
    "        var_in_rule = re.findall('[a-zA-Z]+', r)\n",
    "        var_count = Counter(var_in_rule)\n",
    "        max_count = max(list(var_count.values()))\n",
    "        \n",
    "        if max_count > 1:\n",
    "            dup_feature_in_rule.append(True)\n",
    "        else:\n",
    "            dup_feature_in_rule.append(False)\n",
    "           \n",
    "    if False not in set(dup_feature_in_rule):\n",
    "#         print('wtf')\n",
    "        rule_df = rule_df.head(5)\n",
    "        the_best_defective_rule_str = list(rule_df['rule'])[0]\n",
    "        \n",
    "    else:\n",
    "        rule_df['contain_dup_var'] = dup_feature_in_rule    \n",
    "        the_best_defective_rule_str = rule_df[rule_df['contain_dup_var']==False].iloc[0]['rule']\n",
    "    \n",
    "    return the_best_defective_rule_str\n",
    "\n",
    "def aggregate_list(l):\n",
    "    return np.mean(l), np.median(l)\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "# def test_new_rule_from_rulefit(proj_name):\n",
    "#     global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name)\n",
    "#     all_eval_result = pd.DataFrame()\n",
    "    \n",
    "#     c = 0\n",
    "    \n",
    "# #     py_exp_all_rules = []\n",
    "# #     lime_all_rules = []\n",
    "#     py_exp_all_vars = []\n",
    "#     lime_all_vars = []\n",
    "    \n",
    "#     print('global feature feature importance ranking:')\n",
    "#     print(sort_global_feature(global_model, indep))\n",
    "#     for i in range(0,len(feature_df)):\n",
    "#         X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "#         row_index = str(X_explain.index[0])\n",
    "\n",
    "#         py_exp = pickle.load(open(pyExp_dir+proj_name+'_rulefit_crossoverinterpolation_'+row_index+'_20_rules.pkl','rb'))\n",
    "#         py_exp_local_model = py_exp['local_model']\n",
    "        \n",
    "#         lime_exp = pickle.load(open(pyExp_dir+proj_name+'_lime_'+row_index+'.pkl','rb'))\n",
    "        \n",
    "# #         py_exp_rule = get_rule_str_of_rulefit(py_exp_local_model)\n",
    "#         py_exp_rule_new = get_rule_str_of_rulefit_new_version(py_exp_local_model)\n",
    "#         lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "#         py_exp_pred = eval_rule(py_exp_rule_new, X_explain)[0]\n",
    "#         lime_pred = eval_rule(lime_the_best_defective_rule_str, X_explain)[0]\n",
    "\n",
    "#         if py_exp_pred == 1:\n",
    "#             py_exp_var_in_rule = list(set(re.findall('[a-zA-Z]+', py_exp_rule_new)))\n",
    "#             py_exp_all_vars.extend(py_exp_var_in_rule)\n",
    "#         if lime_pred == 1:\n",
    "#             lime_var_in_rule = list(set(re.findall('[a-zA-Z]+', lime_the_best_defective_rule_str)))\n",
    "#             lime_all_vars.extend(lime_var_in_rule)\n",
    "            \n",
    "# #         py_exp_all_rules.append(py_exp_rule_new)\n",
    "# #         lime_all_rules.append(lime_the_best_defective_rule_str)\n",
    "        \n",
    "# #         eval_result = eval_rule(lime_the_best_defective_rule_str, X_explain)\n",
    "\n",
    "# #         if eval_result[0]:\n",
    "# #             c =c+1\n",
    "\n",
    "    \n",
    "# #     print(len(set(py_exp_all_rules)))\n",
    "# #     print(len(set(lime_all_rules)))\n",
    "    \n",
    "#     print('pyExplainer var count')\n",
    "#     print(Counter(py_exp_all_vars))\n",
    "#     print('-'*100)\n",
    "#     print('LIME var count')\n",
    "#     print(Counter(lime_all_vars))\n",
    "    \n",
    "# print('openstack')\n",
    "# test_new_rule_from_rulefit('openstack')\n",
    "# print('*'*100)\n",
    "# print('qt')\n",
    "# test_new_rule_from_rulefit('qt')\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "def is_in_top_k_global_features(top_k_global_features, the_best_defective_rule_str):\n",
    "    # remove numeric value\n",
    "    new_the_best_defective_rule_str = re.sub('\\d+','', the_best_defective_rule_str)\n",
    "\n",
    "    # remove special characters\n",
    "    new_the_best_defective_rule_str = re.sub('\\W+',' ',new_the_best_defective_rule_str)\n",
    "    splitted_rule = new_the_best_defective_rule_str.split()\n",
    "\n",
    "    local_feature_count = 0\n",
    "    \n",
    "    found_features = set(splitted_rule).intersection(top_k_global_features)\n",
    "    return list(found_features)\n",
    "\n",
    "# def eval_rule(rule, X_explain):\n",
    "#     var_in_rule = re.findall('[a-zA-Z]+',rule)\n",
    "#     rule = rule.replace('&','and') # just for rulefit\n",
    "#     rule = re.sub(r'\\b=\\b','==',rule)\n",
    "# #             rule = rule.replace('=','==')\n",
    "\n",
    "#     var_dict = {}\n",
    "\n",
    "#     for var in var_in_rule:\n",
    "#         var_dict[var] = float(X_explain[var])\n",
    "\n",
    "#     eval_result = eval(rule,var_dict)\n",
    "#     return eval_result\n",
    "\n",
    "        \n",
    "def prepare_data_for_testing(proj_name, global_model_name = 'RF'):\n",
    "    global_model_name = global_model_name.upper()\n",
    "    global_model = pickle.load(open(proj_name+'_'+global_model_name+'_global_model.pkl','rb'))\n",
    "\n",
    "    correctly_predict_df = pd.read_csv(dump_dataframe_dir+proj_name+'_'+global_model_name+'_correctly_predict_as_defective.csv')\n",
    "    correctly_predict_df = correctly_predict_df.set_index('commit_id')\n",
    "\n",
    "    dep = 'defect'\n",
    "    indep = correctly_predict_df.columns[:-3] # exclude the last 3 columns\n",
    "\n",
    "    feature_df = correctly_predict_df.loc[:, indep]\n",
    "    \n",
    "    return global_model, correctly_predict_df, indep, dep, feature_df\n",
    "    \n",
    "\n",
    "\n",
    "# # Global model evaluation\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "def get_prediction_result_df(proj_name, global_model_name):\n",
    "    global_model_name = global_model_name.upper()\n",
    "    if global_model_name not in ['RF','LR']:\n",
    "        print('wrong global model name. the global model name must be RF or LR')\n",
    "        return\n",
    "    \n",
    "    prediction_df_dir = dump_dataframe_dir+proj_name+'_'+global_model_name+'_prediction_result.csv'\n",
    "    correctly_predict_df_dir = dump_dataframe_dir+proj_name+'_'+global_model_name+'_correctly_predict_as_defective.csv'\n",
    "    \n",
    "    if not os.path.exists(prediction_df_dir) or not os.path.exists(correctly_predict_df_dir):\n",
    "        global_model = pickle.load(open(proj_name+'_'+global_model_name+'_global_model.pkl','rb'))\n",
    "\n",
    "        pred = global_model.predict(x_test)\n",
    "        defective_prob = global_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "        prediction_df = x_test.copy()\n",
    "        prediction_df['pred'] = pred\n",
    "        prediction_df['defective_prob'] = defective_prob\n",
    "        prediction_df['defect'] = y_test\n",
    "\n",
    "    #     print('AUC is',roc_auc_score(y_test, defective_prob))\n",
    "        correctly_predict_df = prediction_df[(prediction_df['pred']==1) & (prediction_df['defect']==1)]\n",
    "\n",
    "        print('total correct prediction: {}'.format(str(len(correctly_predict_df))))\n",
    "\n",
    "        prediction_df.to_csv(prediction_df_dir)\n",
    "        correctly_predict_df.to_csv(correctly_predict_df_dir)\n",
    "    \n",
    "    else:\n",
    "        prediction_df = pd.read_csv(prediction_df_dir)\n",
    "        correctly_predict_df = pd.read_csv(correctly_predict_df_dir)\n",
    "        \n",
    "        prediction_df = prediction_df.set_index('commit_id')\n",
    "        correctly_predict_df = correctly_predict_df.set_index('commit_id')\n",
    "        print('total correct prediction: {}'.format(str(len(correctly_predict_df))))\n",
    "        \n",
    "    return prediction_df, correctly_predict_df\n",
    "\n",
    "def get_recall_at_k_percent_effort(percent_effort, result_df_arg, real_buggy_commits):\n",
    "    cum_LOC_k_percent = (percent_effort/100)*result_df_arg.iloc[-1]['cum_LOC']\n",
    "    buggy_line_k_percent =  result_df_arg[result_df_arg['cum_LOC'] <= cum_LOC_k_percent]\n",
    "    buggy_commit = buggy_line_k_percent[buggy_line_k_percent['defect']==True]\n",
    "    recall_k_percent_effort = len(buggy_commit)/float(len(real_buggy_commits))\n",
    "    \n",
    "    return recall_k_percent_effort\n",
    "\n",
    "def eval_global_model(proj_name, prediction_df):\n",
    "    ## since ld metric in openstack is removed by using autospearman, so this code is needed\n",
    "    ## but this is not problem for qt\n",
    "    \n",
    "    if proj_name == 'openstack':\n",
    "        x_train_original, x_test_original = prepare_data_all_metrics(proj_name, mode='all')\n",
    "        prediction_df = prediction_df.copy()\n",
    "#         print('add ld')\n",
    "#         display(x_test_original['ld'])\n",
    "        prediction_df['ld'] = list(x_test_original['ld'])\n",
    "        \n",
    "    prediction_df = prediction_df[['la','ld', 'pred', 'defective_prob' ,'defect']]\n",
    "    prediction_df['LOC'] = prediction_df['la']+prediction_df['ld']\n",
    "    \n",
    "    \n",
    "#     result_df['defect_density'] = result_df['defective_commit_prob']/result_df['LOC']\n",
    "    prediction_df['defect_density'] = prediction_df['defective_prob']/prediction_df['LOC']\n",
    "    prediction_df['actual_defect_density'] = prediction_df['defect']/prediction_df['LOC'] #defect density\n",
    "    \n",
    "    prediction_df = prediction_df.fillna(0)\n",
    "    prediction_df = prediction_df.replace(np.inf, 0)\n",
    "    \n",
    "    prediction_df = prediction_df.sort_values(by='defect_density',ascending=False)\n",
    "#     display(prediction_df.head())\n",
    "#     display(np.sum(prediction_df[prediction_df['la']==0]['defect']))\n",
    "    \n",
    "    actual_result_df = prediction_df.sort_values(by='actual_defect_density',ascending=False)\n",
    "    actual_worst_result_df = prediction_df.sort_values(by='actual_defect_density',ascending=True)\n",
    "\n",
    "    prediction_df['cum_LOC'] = prediction_df['LOC'].cumsum()\n",
    "    actual_result_df['cum_LOC'] = actual_result_df['LOC'].cumsum()\n",
    "    actual_worst_result_df['cum_LOC'] = actual_worst_result_df['LOC'].cumsum()\n",
    "\n",
    "    real_buggy_commits = prediction_df[prediction_df['defect'] == True]\n",
    "    \n",
    "#     display(prediction_df)\n",
    "#     display(real_buggy_commits)\n",
    "    \n",
    "    \n",
    "    AUC = roc_auc_score(prediction_df['defect'], prediction_df['defective_prob'])\n",
    "    f1 = f1_score(prediction_df['defect'], prediction_df['pred'])\n",
    "    \n",
    "    ifa = real_buggy_commits.iloc[0]['cum_LOC']\n",
    "#     print('ifa:',ifa)\n",
    "\n",
    "    cum_LOC_20_percent = 0.2*prediction_df.iloc[-1]['cum_LOC']\n",
    "    buggy_line_20_percent = prediction_df[prediction_df['cum_LOC'] <= cum_LOC_20_percent]\n",
    "    buggy_commit = buggy_line_20_percent[buggy_line_20_percent['defect']==True]\n",
    "    recall_20_percent_effort = len(buggy_commit)/float(len(real_buggy_commits))\n",
    "    \n",
    "    # find P_opt\n",
    "    percent_effort_list = []\n",
    "    predicted_recall_at_percent_effort_list = []\n",
    "    actual_recall_at_percent_effort_list = []\n",
    "    actual_worst_recall_at_percent_effort_list = []\n",
    "    \n",
    "    for percent_effort in np.arange(10,101,10):\n",
    "        predicted_recall_k_percent_effort = get_recall_at_k_percent_effort(percent_effort, prediction_df, real_buggy_commits)\n",
    "        actual_recall_k_percent_effort = get_recall_at_k_percent_effort(percent_effort, actual_result_df, real_buggy_commits)\n",
    "        actual_worst_recall_k_percent_effort = get_recall_at_k_percent_effort(percent_effort, actual_worst_result_df, real_buggy_commits)\n",
    "        \n",
    "        percent_effort_list.append(percent_effort/100)\n",
    "        \n",
    "        predicted_recall_at_percent_effort_list.append(predicted_recall_k_percent_effort)\n",
    "        actual_recall_at_percent_effort_list.append(actual_recall_k_percent_effort)\n",
    "        actual_worst_recall_at_percent_effort_list.append(actual_worst_recall_k_percent_effort)\n",
    "\n",
    "    p_opt = 1 - ((auc(percent_effort_list, actual_recall_at_percent_effort_list) - \n",
    "                 auc(percent_effort_list, predicted_recall_at_percent_effort_list)) /\n",
    "                (auc(percent_effort_list, actual_recall_at_percent_effort_list) -\n",
    "                auc(percent_effort_list, actual_worst_recall_at_percent_effort_list)))\n",
    "\n",
    "    print('AUC: {}, F1: {}, IFA: {}, Recall@20%Effort: {}, Popt: {}'.format(AUC,f1,ifa,recall_20_percent_effort,p_opt))\n",
    "    print(classification_report(prediction_df['defect'], prediction_df['pred']))\n",
    "#     display(cum_LOC_20_percent)\n",
    "#     display(buggy_line_20_percent)\n",
    "# #     display(cum_LOC_20_percent)\n",
    "#     display(buggy_commit)\n",
    "#     print(len(real_buggy_commits))\n",
    "#     display(recall_20_percent_effort)\n",
    "\n",
    "def get_global_model_evaluation_result(proj_name):\n",
    "    print('RF global model result')\n",
    "    rf_prediction_df, rf_correctly_predict_df = get_prediction_result_df(proj_name, 'rf')\n",
    "    eval_global_model(proj_name, rf_prediction_df)\n",
    "\n",
    "    print('-'*100)\n",
    "    \n",
    "    print('LR global model result')\n",
    "    lr_prediction_df, lr_correctly_predict_df = get_prediction_result_df(proj_name, 'lr')\n",
    "    eval_global_model(proj_name, lr_prediction_df)\n",
    "\n",
    "\n",
    "# # RQ3 evaluation\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "def eval_rule(rule, x_df):\n",
    "    var_in_rule = list(set(re.findall('[a-zA-Z]+', rule)))\n",
    "    \n",
    "    rule = re.sub(r'\\b=\\b','==',rule)\n",
    "    if 'or' in var_in_rule:\n",
    "        var_in_rule.remove('or')\n",
    "        \n",
    "    rule = rule.replace('&','and')\n",
    "    \n",
    "    eval_result_list = []\n",
    "    \n",
    "#     print(rule)\n",
    "\n",
    "    for i in range(0,len(x_df)):\n",
    "        x = x_df.iloc[[i]]\n",
    "        col = x.columns\n",
    "        var_dict = {}\n",
    "\n",
    "        for var in var_in_rule:\n",
    "            var_dict[var] = float(x[var])\n",
    "\n",
    "#         print(var_dict)\n",
    "        \n",
    "        # if the rule does not satisfy clean commit, the truth value of the inversed rule when applied to clean commit is true\n",
    "        eval_result = eval(rule,var_dict)\n",
    "        eval_result_list.append(eval_result)\n",
    "        \n",
    "#         print(eval_result)\n",
    "#         break\n",
    "        \n",
    "    return eval_result_list\n",
    "\n",
    "# def summarize_rule_eval_result(py_exp_rule_str, lime_rule_str, x_df, ground_truth):\n",
    "# #     print('Rulefit')\n",
    "#     py_exp_all_eval_result = eval_rule(py_exp_rule_str, x_df)\n",
    "# #     print('LIME')\n",
    "#     lime_all_eval_result = eval_rule(lime_rule_str, x_df)\n",
    "\n",
    "# #     print(py_exp_rule_str)\n",
    "# #     print(lime_rule_str)\n",
    "    \n",
    "# #     tmp_df = x_df.copy()\n",
    "# #     tmp_df['ground_truth'] = ground_truth\n",
    "# #     tmp_df_clean = tmp_df[tmp_df['ground_truth']==False]\n",
    "    \n",
    "# #     display(tmp_df_clean)\n",
    "    \n",
    "#     py_exp_result_df = pd.DataFrame()\n",
    "#     py_exp_result_df['ground_truth'] = ground_truth\n",
    "#     py_exp_result_df['rule_result'] = py_exp_all_eval_result\n",
    "#     py_exp_result_df = py_exp_result_df[py_exp_result_df['rule_result']==True] # get commit that matches counter rule\n",
    "    \n",
    "# #     print('py_exp_result_df')\n",
    "# #     display(py_exp_result_df[py_exp_result_df['ground_truth']==False])\n",
    "# #     print(len(py_exp_result_df))\n",
    "#     # find ratio of clean commit\n",
    "#     py_exp_satisfy_rule_ratio = 100*(len(py_exp_result_df[py_exp_result_df['ground_truth']==False])/len(py_exp_result_df)) if len(py_exp_result_df) > 0 else 0\n",
    "    \n",
    "#     lime_result_df = pd.DataFrame()\n",
    "#     lime_result_df['ground_truth'] = ground_truth\n",
    "#     lime_result_df['rule_result'] = lime_all_eval_result\n",
    "    \n",
    "#     lime_result_df = lime_result_df[lime_result_df['rule_result']==True] # get commit that matches counter rule\n",
    "    \n",
    "# #     print(len(lime_result_df))\n",
    "    \n",
    "#     # find ratio of clean commit\n",
    "# #     print('lime_result_df')\n",
    "# #     display(lime_result_df[lime_result_df['ground_truth']==False])\n",
    "#     lime_satisfy_rule_ratio = 100*(len(lime_result_df[lime_result_df['ground_truth']==False])/len(lime_result_df))  if len(lime_result_df) > 0 else 0\n",
    "    \n",
    "# #     print(len(py_exp_result_df[py_exp_result_df['ground_truth']==False]))\n",
    "# #     print(len(lime_result_df[lime_result_df['ground_truth']==False]))\n",
    "    \n",
    "#     return py_exp_satisfy_rule_ratio, lime_satisfy_rule_ratio\n",
    "\n",
    "def summarize_rule_eval_result(rule_str, x_df):\n",
    "#     print('Rulefit')\n",
    "    all_eval_result = eval_rule(rule_str, x_df)\n",
    "    all_eval_result = np.array(all_eval_result).astype(bool)\n",
    "    \n",
    "#     result_df = pd.DataFrame()\n",
    "#     result_df['ground_truth'] = ground_truth\n",
    "#     result_df['rule_result'] = all_eval_result\n",
    "#     result_df = result_df[result_df['rule_result']==True] # get commit that matches counter rule\n",
    "    \n",
    "#     print('py_exp_result_df')\n",
    "#     display(py_exp_result_df[py_exp_result_df['ground_truth']==False])\n",
    "#     print(len(py_exp_result_df))\n",
    "    # find ratio of clean commit\n",
    "#     satisfy_rule_ratio = 100*(len(result_df[result_df['ground_truth']==False])/len(result_df)) if len(result_df) > 0 else 0\n",
    "\n",
    "    return all_eval_result\n",
    "\n",
    "'''\n",
    "    input:\n",
    "        local_model: local model of RuleFit\n",
    "        X_explain: an instance to be explained\n",
    "        \n",
    "    return:\n",
    "        g2_guide, g4_guide (string)\n",
    "        more info of g2/g4 guidance refers to SQAPlanner paper\n",
    "'''\n",
    "\n",
    "def get_g2_g4_guidance(local_model, X_explain):\n",
    "    rules = local_model.get_rules()\n",
    "    rules = rules[(rules['type']=='rule') & (rules['coef'] < 0) & (rules['importance'] > 0)]\n",
    "    rules_list = list(rules['rule'])\n",
    "    \n",
    "    rule_eval_result = []\n",
    "\n",
    "    for r in rules_list:\n",
    "        py_exp_pred = eval_rule(r, X_explain)[0]\n",
    "        rule_eval_result.append(py_exp_pred)\n",
    "        \n",
    "    rules['is_satisfy_instance'] = rule_eval_result\n",
    "    \n",
    "    g2_guide_df = rules[rules['is_satisfy_instance']==True]\n",
    "    g4_guide_df = rules[rules['is_satisfy_instance']==False]\n",
    "\n",
    "    g2_guide_df = g2_guide_df.sort_values(by='importance', ascending=False)\n",
    "    g4_guide_df = g4_guide_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    g2_guide = g2_guide_df.iloc[0]['rule']\n",
    "    g4_guide = g4_guide_df.iloc[0]['rule']\n",
    "    \n",
    "    return g2_guide, g4_guide\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "def test_rule(proj_name):\n",
    "    global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_namez)\n",
    "    x_test, y_test = prepare_data(proj_name, mode = 'test')\n",
    "    \n",
    "    rq3_eval_result = pd.DataFrame() # for train data\n",
    "\n",
    "    py_exp_guide = []\n",
    "    lime_guide = []\n",
    "    \n",
    "    for i in range(0,len(feature_df)):\n",
    "        X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "        row_index = str(X_explain.index[0])\n",
    "\n",
    "        py_exp = pickle.load(open(pyExp_dir+proj_name+'_rulefit_crossoverinterpolation_'+row_index+'.pkl','rb'))\n",
    "        lime_exp = pickle.load(open(pyExp_dir+proj_name+'_lime_'+row_index+'.pkl','rb'))\n",
    "\n",
    "        py_exp_local_model = py_exp['local_model']\n",
    "        lime_exp_local_model = lime_exp['local_model']\n",
    "        \n",
    "        py_exp_the_best_defective_rule_str = get_rule_str_of_rulefit(py_exp_local_model)\n",
    "#         print(py_exp_the_best_defective_rule_str)\n",
    "        \n",
    "        total_cond_in_py_exp = len(py_exp_the_best_defective_rule_str.split('&'))\n",
    "        \n",
    "        lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "        py_exp_pred = eval_rule(py_exp_the_best_defective_rule_str, X_explain)[0]\n",
    "        lime_pred = eval_rule(lime_the_best_defective_rule_str, X_explain)[0]\n",
    "\n",
    "#         print(py_exp_pred, lime_pred)\n",
    "        if py_exp_pred:\n",
    "            py_exp_the_best_defective_rule_str = flip_rule(py_exp_the_best_defective_rule_str)\n",
    "            py_exp_guide.append(py_exp_the_best_defective_rule_str)\n",
    "\n",
    "        if lime_pred:\n",
    "            lime_the_best_defective_rule_str = flip_rule(lime_the_best_defective_rule_str)\n",
    "            lime_guide.append(lime_the_best_defective_rule_str)\n",
    "        \n",
    "    print(set(py_exp_guide))\n",
    "    print('total guidance:',len(set(py_exp_guide)))\n",
    "    print('-'*100)\n",
    "    print(set(lime_guide))\n",
    "    print('total guidance:',len(set(lime_guide)))\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "def eval_PyExplainer_guidance(proj_name, global_model, method_name, row_index, guidance, x_test, y_test_flip , flip=False):\n",
    "    guidance_list = guidance.split('&')\n",
    "    \n",
    "    guide_eval_result = pd.DataFrame()\n",
    "    \n",
    "    for condition in guidance_list:\n",
    "        if flip:\n",
    "            condition = flip_rule(condition)\n",
    "            \n",
    "        py_exp_guidance_eval = summarize_rule_eval_result(condition, x_test)\n",
    "\n",
    "        guide_prec = precision_score(y_test_flip, py_exp_guidance_eval)\n",
    "        guide_rec = recall_score(y_test_flip, py_exp_guidance_eval)\n",
    "\n",
    "        py_exp_serie_test = pd.Series(data=[proj_name, row_index, method_name, global_model,condition, guide_prec, guide_rec])\n",
    "        guide_eval_result = guide_eval_result.append(py_exp_serie_test,ignore_index=True)\n",
    "        \n",
    "    return guide_eval_result\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "def get_g1_guidance(local_model, X_explain):\n",
    "    rules = local_model.get_rules()\n",
    "    rules = rules[(rules['type']=='rule') & (rules['coef'] > 0) & (rules['importance'] > 0)]\n",
    "    rules_list = list(rules['rule'])\n",
    "    \n",
    "    rule_eval_result = []\n",
    "\n",
    "    for r in rules_list:\n",
    "        py_exp_pred = eval_rule(r, X_explain)[0]\n",
    "        rule_eval_result.append(py_exp_pred)\n",
    "        \n",
    "    rules['is_satisfy_instance'] = rule_eval_result\n",
    "    \n",
    "    g1_guide_df = rules[rules['is_satisfy_instance']==True]\n",
    "\n",
    "    g1_guide_df = g1_guide_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    g1_guide = g1_guide_df.iloc[0]['rule']\n",
    "    \n",
    "    return g1_guide\n",
    "\n",
    "def rq3_eval(proj_name, global_model_name):\n",
    "    global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name, global_model_name)\n",
    "    x_test, y_test = prepare_data(proj_name, mode = 'test')\n",
    "    \n",
    "    y_test_flip = [False if val else True for val in y_test]\n",
    "    \n",
    "    rq3_explanation_result = pd.DataFrame()\n",
    "    \n",
    "    pyexp_guidance_result_list = []\n",
    "    lime_guidance_result_df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0,len(feature_df)):\n",
    "\n",
    "        X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "        row_index = str(X_explain.index[0])\n",
    "\n",
    "        exp_obj = pickle.load(open(pyExp_dir+proj_name+'_'+global_model_name+'_all_explainer_'+row_index+'.pkl','rb'))\n",
    "        py_exp = exp_obj['pyExplainer']\n",
    "        lime_exp = exp_obj['LIME']\n",
    "\n",
    "        # load local models\n",
    "        py_exp_local_model = py_exp['local_model']\n",
    "        lime_exp_local_model = lime_exp['local_model']\n",
    "        \n",
    "        # generate explanations                \n",
    "        py_exp_the_best_defective_rule_str = get_g1_guidance(py_exp_local_model, X_explain)\n",
    "        lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "        # check whether explanations apply to the instance to be explained\n",
    "        py_exp_pred = eval_rule(py_exp_the_best_defective_rule_str, X_explain)[0]\n",
    "        lime_pred = eval_rule(lime_the_best_defective_rule_str, X_explain)[0]\n",
    "\n",
    "        # split rule to get list of conditions\n",
    "        condition_list = py_exp_the_best_defective_rule_str.split('&')\n",
    "\n",
    "        # for explanations\n",
    "        for condition in condition_list:\n",
    "            condition = condition.strip()\n",
    "\n",
    "            py_exp_rule_eval = summarize_rule_eval_result(condition, x_test)\n",
    "\n",
    "            rule_prec = precision_score(y_test, py_exp_rule_eval)\n",
    "            rule_rec = recall_score(y_test, py_exp_rule_eval)\n",
    "\n",
    "            py_exp_serie_test = pd.Series(data=[proj_name, row_index, 'pyExplainer',global_model_name, condition, rule_prec, rule_rec, py_exp_pred])\n",
    "            rq3_explanation_result = rq3_explanation_result.append(py_exp_serie_test,ignore_index=True)\n",
    "\n",
    "        # for guidance\n",
    "        g2_guide, g4_guide = get_g2_g4_guidance(py_exp_local_model, X_explain)\n",
    "\n",
    "        flip_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpFlip', row_index,\n",
    "                                                           py_exp_the_best_defective_rule_str, x_test, y_test_flip, flip=True)\n",
    "        g2_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpG2', row_index,\n",
    "                                                           g2_guide, x_test, y_test_flip, flip=False)\n",
    "        g4_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpG4', row_index,\n",
    "                                                           g4_guide, x_test, y_test_flip, flip=False)\n",
    "\n",
    "        pyexp_guidance_result_list.append(flip_guide_eval_result)\n",
    "        pyexp_guidance_result_list.append(g2_guide_eval_result)\n",
    "        pyexp_guidance_result_list.append(g4_guide_eval_result)\n",
    "        # PyExp END\n",
    "        \n",
    "       \n",
    "        # LIME START\n",
    "        lime_rule_eval = summarize_rule_eval_result(lime_the_best_defective_rule_str, x_test)\n",
    "\n",
    "        rule_prec = precision_score(y_test, lime_rule_eval)\n",
    "        rule_rec = recall_score(y_test, lime_rule_eval)\n",
    "\n",
    "        lime_serie_test = pd.Series(data=[proj_name, row_index, 'LIME',global_model_name, lime_the_best_defective_rule_str, rule_prec, rule_rec, lime_pred])\n",
    "        rq3_explanation_result = rq3_explanation_result.append(lime_serie_test,ignore_index=True)\n",
    "\n",
    "        lime_guidance = flip_rule(lime_the_best_defective_rule_str)\n",
    "        lime_guidance_eval = summarize_rule_eval_result(lime_guidance, x_test)\n",
    "#             tn, fp, fn, tp = confusion_matrix(y_test, lime_rule_eval, labels=[1,0]).ravel()\n",
    "#             tp_rate = tp/(tp+fn)\n",
    "#             tn_rate = tn/(tn+fp)\n",
    "\n",
    "        guide_prec = precision_score(y_test_flip, lime_guidance_eval)\n",
    "        guide_rec = recall_score(y_test_flip, lime_guidance_eval)\n",
    "\n",
    "        lime_serie_test = pd.Series(data=[proj_name, row_index, 'LIME', global_model_name, lime_guidance, guide_prec, guide_rec])\n",
    "        lime_guidance_result_df = lime_guidance_result_df.append(lime_serie_test, ignore_index=True)\n",
    "            \n",
    "        print('finished {} from {} commits'.format(str(i+1),len(feature_df)))\n",
    "        \n",
    "        \n",
    "    pyexp_guidance_result_df = pd.concat(pyexp_guidance_result_list)\n",
    "    \n",
    "    rq3_guidance_result = pd.concat([pyexp_guidance_result_df, lime_guidance_result_df])\n",
    "    \n",
    "    \n",
    "    \n",
    "    rq3_explanation_result.columns = ['project','commit_id','method','global_model','explanation','precision','recall', 'isSatisfy']\n",
    "    rq3_guidance_result.columns = ['project','commit_id','method', 'global_model','guidance','precision','recall']\n",
    "\n",
    "    rq3_explanation_result.to_csv(result_dir+'RQ3_'+proj_name+'_'+global_model_name+'_explanation_eval_split_rulefit_condition.csv',index=False)\n",
    "    rq3_guidance_result.to_csv(result_dir+'RQ3_'+proj_name+'_'+global_model_name+'_guidance_eval_split_rulefit_condition.csv',index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_probs(X_input, global_model, input_guidance, input_SD):\n",
    "\n",
    "    k_percent = 10\n",
    "    prob_og = global_model.predict_proba(X_input)[0][1]\n",
    "\n",
    "\n",
    "    output_df = pd.DataFrame()\n",
    "    # 1) Revised values must not be negative -> if val < 0 then val = 0\n",
    "    # 2) Revised values must not be lesser/greater than the actual values for < / > operations\n",
    "    # E.g., {LOC < 50} => Clean and the actual LOC is 30: \n",
    "    # For a 10-percent decrease approach, the revised value according to the threshold is 45\n",
    "    # In this case (Actual < Revised), we apply the 10-percent decrease approach to the actual value instead of the threshold.\n",
    "    # Thus, the final revised value is 27 (10-percent decrease from 30)\n",
    "    # There are 2 approaches:\n",
    "    # (1) n-percent increase/decrease, e.g., 10-percent\n",
    "    # (2) an SD_train increase/decrease, e.g., 1SD\n",
    "\n",
    "    X_revised_percent = X_input.copy()\n",
    "    X_revised_sd = X_input.copy()\n",
    "    for guidance_i in input_guidance.split('&'):\n",
    "        tmp_g = guidance_i.strip().split(' ')\n",
    "#         print(tmp_g)\n",
    "#         print(len(tmp_g))\n",
    "        if len(tmp_g) != 3:\n",
    "            continue\n",
    "\n",
    "        revised_var = tmp_g[0]    \n",
    "        revised_opr = tmp_g[1] \n",
    "        actual_val = X_input[revised_var][0]\n",
    "        for approach_i in ['percent', 'sd']:\n",
    "\n",
    "#             print('Approach', approach_i)\n",
    "            if approach_i == 'percent':\n",
    "\n",
    "                if '<' in revised_opr:\n",
    "                    # < or <=\n",
    "                    revised_from_threshold = float(tmp_g[2]) * (100 - k_percent) / 100.0\n",
    "                    revised_from_actual = X_explain[revised_var][0] * (100 - k_percent) / 100.0\n",
    "                    # the revised value from threshold must not greater than the actual values\n",
    "                    if revised_from_threshold > actual_val:\n",
    "                        actual_revised_value = revised_from_actual\n",
    "                    else:\n",
    "                        actual_revised_value = revised_from_threshold\n",
    "                else:\n",
    "                    # > or >=\n",
    "                    revised_from_threshold = float(tmp_g[2]) * (100 + k_percent) / 100.0\n",
    "                    revised_from_actual = X_explain[revised_var][0] * (100 + k_percent) / 100.0\n",
    "                    # the revised value from threshold must not less than the actual values\n",
    "                    if revised_from_threshold < actual_val:\n",
    "                        actual_revised_value = revised_from_actual\n",
    "                    else:\n",
    "                        actual_revised_value = revised_from_threshold\n",
    "                   \n",
    "                # the revised value must not be negative\n",
    "                if actual_revised_value < 0:\n",
    "                    actual_revised_value = 0\n",
    "                X_revised_percent[revised_var] = actual_revised_value\n",
    "                \n",
    "            else: #SD approach\n",
    "\n",
    "                if '<' in revised_opr:\n",
    "                    # < or <=\n",
    "                    revised_from_threshold = float(tmp_g[2]) - input_SD[revised_var]\n",
    "                    revised_from_actual = X_explain[revised_var][0] - input_SD[revised_var]\n",
    "                    # the revised value from threshold must not greater than the actual values\n",
    "                    if revised_from_threshold > actual_val:\n",
    "                        actual_revised_value = revised_from_actual\n",
    "                    else:\n",
    "                        actual_revised_value = revised_from_threshold\n",
    "                else:\n",
    "                    # > or >=\n",
    "                    revised_from_threshold = float(tmp_g[2]) + input_SD[revised_var]\n",
    "                    revised_from_actual = X_explain[revised_var][0] + input_SD[revised_var]\n",
    "                    # the revised value from threshold must not less than the actual values\n",
    "                    if revised_from_threshold < actual_val:\n",
    "                        actual_revised_value = revised_from_actual\n",
    "                    else:\n",
    "                        actual_revised_value = revised_from_threshold\n",
    "\n",
    "                # the revised value must not be negative\n",
    "                if actual_revised_value < 0:\n",
    "                    actual_revised_value = 0\n",
    "                \n",
    "                X_revised_sd[revised_var] = actual_revised_value\n",
    "\n",
    "    prob_revised_percent = global_model.predict_proba(X_revised_percent)[0][1]\n",
    "    prob_revised_sd = global_model.predict_proba(X_revised_sd)[0][1]\n",
    "    \n",
    "    tmp_out = pd.Series(data=[input_guidance, prob_og, prob_revised_percent, prob_revised_sd])\n",
    "    output_df = output_df.append(tmp_out,ignore_index=True)\n",
    "    if len(output_df) == 0:\n",
    "        return []\n",
    "    output_df.columns = ['guidance', 'probOg', 'probRevisedPercent', 'probRevisedSD']\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_if_analysis(proj_name, global_model_name):\n",
    "    global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name, global_model_name)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = prepare_data(proj_name, mode = 'all')\n",
    "    y_test_flip = [False if val else True for val in y_test]\n",
    "\n",
    "    rq3_explanation_result = pd.DataFrame()\n",
    "\n",
    "    pyexp_guidance_result_list = []\n",
    "    lime_guidance_result_df = pd.DataFrame()\n",
    "\n",
    "    x_train_sd = x_train.std()\n",
    "    \n",
    "    all_df = pd.DataFrame()\n",
    "\n",
    "    get_revised_probs = get_combined_probs\n",
    "\n",
    "    for i in range(0,len(feature_df)):\n",
    "\n",
    "        tmp_df = pd.DataFrame()\n",
    "\n",
    "        X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "        row_index = str(X_explain.index[0])\n",
    "\n",
    "        exp_obj = pickle.load(open(pyExp_dir+proj_name+'_'+global_model_name+'_all_explainer_'+row_index+'.pkl','rb'))\n",
    "        py_exp = exp_obj['pyExplainer']\n",
    "        lime_exp = exp_obj['LIME']\n",
    "\n",
    "        # load local models\n",
    "        py_exp_local_model = py_exp['local_model']\n",
    "        lime_exp_local_model = lime_exp['local_model']\n",
    "\n",
    "        # generate explanations                \n",
    "        py_exp_the_best_defective_rule_str = get_g1_guidance(py_exp_local_model, X_explain)\n",
    "        lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "        # generate guidance\n",
    "        ## PyExplainer - PyFlip, PyG2, PyG4\n",
    "\n",
    "        pyFlip = flip_rule(py_exp_the_best_defective_rule_str)\n",
    "        pyG2, pyG4 = get_g2_g4_guidance(py_exp_local_model, X_explain)\n",
    "\n",
    "\n",
    "        tmp_df_i = get_revised_probs(X_explain, global_model, pyFlip, x_train_sd)\n",
    "        if len(tmp_df_i) > 0:\n",
    "            tmp_df_i['gtype'] = 'pyFlip'\n",
    "            tmp_df = tmp_df.append(tmp_df_i)\n",
    "\n",
    "        tmp_df_i = get_revised_probs(X_explain, global_model, pyG2, x_train_sd)\n",
    "        if len(tmp_df_i) > 0:\n",
    "            tmp_df_i['gtype'] = 'pyG2'\n",
    "            tmp_df = tmp_df.append(tmp_df_i)\n",
    "\n",
    "        tmp_df_i = get_revised_probs(X_explain, global_model, pyG4, x_train_sd)\n",
    "        if len(tmp_df_i) > 0:\n",
    "            tmp_df_i['gtype'] = 'pyG4'\n",
    "            tmp_df = tmp_df.append(tmp_df_i)\n",
    "\n",
    "\n",
    "        # LIME START\n",
    "        lime_guidance = flip_rule(lime_the_best_defective_rule_str)\n",
    "\n",
    "        tmp_df_i = get_revised_probs(X_explain, global_model, lime_guidance, x_train_sd)\n",
    "        if len(tmp_df_i) > 0:\n",
    "            tmp_df_i['gtype'] = 'LIMEFlip'\n",
    "            tmp_df = tmp_df.append(tmp_df_i)\n",
    "\n",
    "        tmp_df['commit_id'] = row_index\n",
    "        tmp_df['model'] = global_model_name\n",
    "        tmp_df['project'] = proj_name\n",
    "        all_df = all_df.append(tmp_df)\n",
    "        \n",
    "    rq4_result_df.to_csv(result_dir+'RQ4_'+proj_name+'_'+global_model_name+'_guidance_eval_no_dup_original_rulefit_condition_new.csv',index=False)\n",
    "\n",
    "    all_df.to_csv(result_dir+'RQ4_'+proj_name+'_'+global_model_name+'_combined_prob_from_guidance.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'openstack'\n",
    "global_model_name = 'RF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name, global_model_name)\n",
    "\n",
    "x_train, y_train = prepare_data(proj_name, mode = 'train')\n",
    "\n",
    "x_test, y_test = prepare_data(proj_name, mode = 'test')\n",
    "\n",
    "y_test_flip = [False if val else True for val in y_test]\n",
    "\n",
    "rq3_explanation_result = pd.DataFrame()\n",
    "\n",
    "pyexp_guidance_result_list = []\n",
    "lime_guidance_result_df = pd.DataFrame()\n",
    "\n",
    "x_train_sd = x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openstack START\n",
      "RF START\n",
      "index 0\n",
      "index 1\n",
      "index 2\n",
      "index 3\n",
      "index 4\n",
      "index 5\n",
      "index 6\n",
      "index 7\n",
      "index 8\n",
      "index 9\n",
      "index 10\n",
      "index 11\n",
      "index 12\n",
      "index 13\n",
      "index 14\n",
      "index 15\n",
      "index 16\n",
      "index 17\n",
      "index 18\n",
      "index 19\n",
      "index 20\n",
      "index 21\n",
      "index 22\n",
      "index 23\n",
      "index 24\n",
      "index 25\n",
      "index 26\n",
      "index 27\n",
      "index 28\n",
      "index 29\n",
      "index 30\n",
      "index 31\n",
      "index 32\n",
      "index 33\n",
      "index 34\n",
      "index 35\n",
      "index 36\n",
      "index 37\n",
      "index 38\n",
      "index 39\n",
      "index 40\n",
      "index 41\n",
      "index 42\n",
      "index 43\n",
      "index 44\n",
      "index 45\n",
      "index 46\n",
      "index 47\n",
      "index 48\n",
      "index 49\n",
      "index 50\n",
      "index 51\n",
      "index 52\n",
      "index 53\n",
      "index 54\n",
      "index 55\n",
      "index 56\n",
      "index 57\n",
      "index 58\n",
      "index 59\n",
      "index 60\n",
      "index 61\n",
      "index 62\n",
      "index 63\n",
      "index 64\n",
      "index 65\n",
      "index 66\n",
      "index 67\n",
      "index 68\n",
      "index 69\n",
      "index 70\n",
      "index 71\n",
      "index 72\n",
      "index 73\n",
      "index 74\n",
      "index 75\n",
      "index 76\n",
      "index 77\n",
      "index 78\n",
      "index 79\n",
      "index 80\n",
      "index 81\n",
      "index 82\n",
      "index 83\n",
      "index 84\n",
      "index 85\n",
      "index 86\n",
      "index 87\n",
      "index 88\n",
      "index 89\n",
      "index 90\n",
      "index 91\n",
      "index 92\n",
      "index 93\n",
      "index 94\n",
      "index 95\n",
      "index 96\n",
      "index 97\n",
      "index 98\n",
      "index 99\n",
      "index 100\n",
      "index 101\n",
      "index 102\n",
      "index 103\n",
      "index 104\n",
      "index 105\n",
      "index 106\n",
      "index 107\n",
      "index 108\n",
      "index 109\n",
      "index 110\n",
      "index 111\n",
      "index 112\n",
      "index 113\n",
      "index 114\n",
      "index 115\n",
      "index 116\n",
      "index 117\n",
      "index 118\n",
      "index 119\n",
      "index 120\n",
      "index 121\n",
      "index 122\n",
      "index 123\n",
      "index 124\n",
      "index 125\n",
      "index 126\n",
      "index 127\n",
      "index 128\n",
      "index 129\n",
      "index 130\n",
      "index 131\n",
      "index 132\n",
      "index 133\n",
      "index 134\n",
      "index 135\n",
      "index 136\n",
      "index 137\n",
      "index 138\n",
      "index 139\n",
      "index 140\n",
      "index 141\n",
      "index 142\n",
      "index 143\n",
      "index 144\n",
      "index 145\n",
      "index 146\n",
      "index 147\n",
      "index 148\n",
      "index 149\n",
      "index 150\n",
      "index 151\n",
      "index 152\n",
      "index 153\n",
      "index 154\n",
      "index 155\n",
      "index 156\n",
      "index 157\n",
      "index 158\n",
      "index 159\n",
      "index 160\n",
      "index 161\n",
      "index 162\n",
      "index 163\n",
      "index 164\n",
      "index 165\n",
      "index 166\n",
      "index 167\n",
      "index 168\n",
      "index 169\n",
      "index 170\n",
      "index 171\n",
      "index 172\n",
      "index 173\n",
      "index 174\n",
      "index 175\n",
      "index 176\n",
      "index 177\n",
      "index 178\n",
      "index 179\n",
      "index 180\n",
      "index 181\n",
      "index 182\n",
      "index 183\n",
      "index 184\n",
      "index 185\n",
      "index 186\n",
      "index 187\n",
      "index 188\n",
      "index 189\n",
      "index 190\n",
      "index 191\n",
      "index 192\n",
      "index 193\n",
      "index 194\n",
      "index 195\n",
      "index 196\n",
      "index 197\n",
      "LR START\n",
      "index 0\n",
      "index 1\n",
      "index 2\n",
      "index 3\n",
      "index 4\n",
      "index 5\n",
      "index 6\n",
      "index 7\n",
      "index 8\n",
      "index 9\n",
      "index 10\n",
      "index 11\n",
      "index 12\n",
      "index 13\n",
      "index 14\n",
      "index 15\n",
      "index 16\n",
      "index 17\n",
      "index 18\n",
      "index 19\n",
      "index 20\n",
      "index 21\n",
      "index 22\n",
      "index 23\n",
      "index 24\n",
      "index 25\n",
      "index 26\n",
      "index 27\n",
      "index 28\n",
      "index 29\n",
      "index 30\n",
      "index 31\n",
      "index 32\n",
      "index 33\n",
      "index 34\n",
      "index 35\n",
      "index 36\n",
      "index 37\n",
      "index 38\n",
      "index 39\n",
      "index 40\n",
      "index 41\n",
      "index 42\n",
      "index 43\n",
      "index 44\n",
      "index 45\n",
      "index 46\n",
      "index 47\n",
      "index 48\n",
      "index 49\n",
      "index 50\n",
      "index 51\n",
      "index 52\n",
      "index 53\n",
      "index 54\n",
      "index 55\n",
      "index 56\n",
      "index 57\n",
      "index 58\n",
      "index 59\n",
      "index 60\n",
      "index 61\n",
      "index 62\n",
      "index 63\n",
      "index 64\n",
      "index 65\n",
      "index 66\n",
      "index 67\n",
      "index 68\n",
      "index 69\n",
      "index 70\n",
      "index 71\n",
      "index 72\n",
      "index 73\n",
      "index 74\n",
      "index 75\n",
      "index 76\n",
      "index 77\n",
      "index 78\n",
      "index 79\n",
      "index 80\n",
      "index 81\n",
      "index 82\n",
      "index 83\n",
      "index 84\n",
      "index 85\n",
      "index 86\n",
      "index 87\n",
      "index 88\n",
      "index 89\n",
      "index 90\n",
      "index 91\n",
      "index 92\n",
      "index 93\n",
      "index 94\n",
      "index 95\n",
      "index 96\n",
      "index 97\n",
      "index 98\n",
      "index 99\n",
      "index 100\n",
      "index 101\n",
      "index 102\n",
      "index 103\n",
      "index 104\n",
      "index 105\n",
      "index 106\n",
      "index 107\n",
      "index 108\n",
      "index 109\n",
      "index 110\n",
      "index 111\n",
      "index 112\n",
      "index 113\n",
      "index 114\n",
      "index 115\n",
      "index 116\n",
      "index 117\n",
      "index 118\n",
      "index 119\n",
      "index 120\n",
      "index 121\n",
      "index 122\n",
      "index 123\n",
      "index 124\n",
      "index 125\n",
      "index 126\n",
      "index 127\n",
      "index 128\n",
      "index 129\n",
      "index 130\n",
      "index 131\n",
      "index 132\n",
      "index 133\n",
      "index 134\n",
      "index 135\n",
      "index 136\n",
      "index 137\n",
      "index 138\n",
      "index 139\n",
      "index 140\n",
      "index 141\n",
      "index 142\n",
      "index 143\n",
      "index 144\n",
      "index 145\n",
      "index 146\n",
      "index 147\n",
      "index 148\n",
      "index 149\n",
      "index 150\n",
      "index 151\n",
      "index 152\n",
      "index 153\n",
      "index 154\n",
      "index 155\n",
      "index 156\n",
      "index 157\n",
      "index 158\n",
      "index 159\n",
      "index 160\n",
      "index 161\n",
      "index 162\n",
      "index 163\n",
      "index 164\n",
      "index 165\n",
      "index 166\n",
      "index 167\n",
      "index 168\n",
      "index 169\n",
      "index 170\n",
      "index 171\n",
      "index 172\n",
      "index 173\n",
      "index 174\n",
      "index 175\n",
      "index 176\n",
      "index 177\n",
      "index 178\n",
      "index 179\n",
      "index 180\n",
      "index 181\n",
      "index 182\n",
      "index 183\n",
      "index 184\n",
      "index 185\n",
      "index 186\n",
      "index 187\n",
      "index 188\n",
      "index 189\n",
      "index 190\n",
      "index 191\n",
      "index 192\n",
      "index 193\n",
      "index 194\n",
      "index 195\n",
      "index 196\n",
      "index 197\n",
      "index 198\n",
      "index 199\n",
      "index 200\n",
      "index 201\n",
      "index 202\n",
      "index 203\n",
      "index 204\n",
      "index 205\n",
      "index 206\n",
      "index 207\n",
      "index 208\n",
      "index 209\n",
      "index 210\n",
      "index 211\n",
      "index 212\n",
      "index 213\n",
      "index 214\n",
      "index 215\n",
      "index 216\n",
      "index 217\n",
      "index 218\n",
      "index 219\n",
      "index 220\n",
      "index 221\n",
      "index 222\n",
      "index 223\n",
      "index 224\n",
      "index 225\n",
      "index 226\n",
      "index 227\n",
      "index 228\n",
      "index 229\n",
      "index 230\n",
      "index 231\n",
      "index 232\n",
      "index 233\n",
      "index 234\n",
      "index 235\n",
      "index 236\n",
      "index 237\n",
      "index 238\n",
      "index 239\n",
      "index 240\n",
      "index 241\n",
      "index 242\n",
      "index 243\n",
      "index 244\n",
      "index 245\n",
      "index 246\n",
      "index 247\n",
      "index 248\n",
      "index 249\n",
      "index 250\n",
      "index 251\n",
      "index 252\n",
      "index 253\n",
      "index 254\n",
      "index 255\n",
      "index 256\n",
      "index 257\n",
      "index 258\n",
      "index 259\n",
      "index 260\n",
      "index 261\n",
      "index 262\n",
      "index 263\n",
      "index 264\n",
      "index 265\n",
      "index 266\n",
      "index 267\n",
      "index 268\n",
      "index 269\n",
      "index 270\n",
      "index 271\n",
      "index 272\n",
      "index 273\n",
      "index 274\n",
      "index 275\n",
      "index 276\n",
      "index 277\n",
      "index 278\n",
      "index 279\n",
      "index 280\n",
      "index 281\n",
      "index 282\n",
      "index 283\n",
      "index 284\n",
      "index 285\n",
      "index 286\n",
      "index 287\n",
      "index 288\n",
      "index 289\n",
      "index 290\n",
      "index 291\n",
      "index 292\n",
      "index 293\n",
      "index 294\n",
      "index 295\n",
      "index 296\n",
      "index 297\n",
      "index 298\n",
      "index 299\n",
      "index 300\n",
      "index 301\n",
      "index 302\n",
      "index 303\n",
      "index 304\n",
      "index 305\n",
      "index 306\n",
      "index 307\n",
      "index 308\n",
      "index 309\n",
      "index 310\n",
      "index 311\n",
      "index 312\n",
      "index 313\n",
      "index 314\n",
      "index 315\n",
      "index 316\n",
      "index 317\n",
      "index 318\n",
      "index 319\n",
      "index 320\n",
      "index 321\n",
      "index 322\n",
      "index 323\n",
      "index 324\n",
      "index 325\n",
      "index 326\n",
      "index 327\n",
      "index 328\n",
      "index 329\n",
      "index 330\n",
      "index 331\n",
      "index 332\n",
      "index 333\n",
      "index 334\n",
      "index 335\n",
      "index 336\n",
      "index 337\n",
      "index 338\n",
      "index 339\n",
      "index 340\n",
      "index 341\n",
      "index 342\n",
      "index 343\n",
      "index 344\n",
      "index 345\n",
      "index 346\n",
      "index 347\n",
      "index 348\n",
      "index 349\n",
      "index 350\n",
      "index 351\n",
      "index 352\n",
      "index 353\n",
      "index 354\n",
      "index 355\n",
      "index 356\n",
      "index 357\n",
      "index 358\n",
      "index 359\n",
      "index 360\n",
      "index 361\n",
      "index 362\n",
      "index 363\n",
      "index 364\n",
      "index 365\n",
      "index 366\n",
      "index 367\n",
      "index 368\n",
      "index 369\n",
      "index 370\n",
      "index 371\n",
      "index 372\n",
      "index 373\n",
      "index 374\n",
      "index 375\n",
      "qt START\n",
      "RF START\n",
      "index 0\n",
      "index 1\n",
      "index 2\n",
      "index 3\n",
      "index 4\n",
      "index 5\n",
      "index 6\n",
      "index 7\n",
      "index 8\n",
      "index 9\n",
      "index 10\n",
      "index 11\n",
      "index 12\n",
      "index 13\n",
      "index 14\n",
      "index 15\n",
      "index 16\n",
      "index 17\n",
      "index 18\n",
      "index 19\n",
      "index 20\n",
      "index 21\n",
      "index 22\n",
      "index 23\n",
      "index 24\n",
      "index 25\n",
      "index 26\n",
      "index 27\n",
      "index 28\n",
      "index 29\n",
      "index 30\n",
      "index 31\n",
      "index 32\n",
      "index 33\n",
      "index 34\n",
      "index 35\n",
      "index 36\n",
      "index 37\n",
      "index 38\n",
      "index 39\n",
      "index 40\n",
      "index 41\n",
      "index 42\n",
      "index 43\n",
      "index 44\n",
      "index 45\n",
      "index 46\n",
      "index 47\n",
      "index 48\n",
      "index 49\n",
      "index 50\n",
      "index 51\n",
      "index 52\n",
      "index 53\n",
      "index 54\n",
      "index 55\n",
      "index 56\n",
      "index 57\n",
      "index 58\n",
      "index 59\n",
      "index 60\n",
      "index 61\n",
      "index 62\n",
      "index 63\n",
      "index 64\n",
      "index 65\n",
      "index 66\n",
      "index 67\n",
      "index 68\n",
      "index 69\n",
      "index 70\n",
      "index 71\n",
      "index 72\n",
      "index 73\n",
      "index 74\n",
      "index 75\n",
      "index 76\n",
      "index 77\n",
      "index 78\n",
      "LR START\n",
      "index 0\n",
      "index 1\n",
      "index 2\n",
      "index 3\n",
      "index 4\n",
      "index 5\n",
      "index 6\n",
      "index 7\n",
      "index 8\n",
      "index 9\n",
      "index 10\n",
      "index 11\n",
      "index 12\n",
      "index 13\n",
      "index 14\n",
      "index 15\n",
      "index 16\n",
      "index 17\n",
      "index 18\n",
      "index 19\n",
      "index 20\n",
      "index 21\n",
      "index 22\n",
      "index 23\n",
      "index 24\n",
      "index 25\n",
      "index 26\n",
      "index 27\n",
      "index 28\n",
      "index 29\n",
      "index 30\n",
      "index 31\n",
      "index 32\n",
      "index 33\n",
      "index 34\n",
      "index 35\n",
      "index 36\n",
      "index 37\n",
      "index 38\n",
      "index 39\n",
      "index 40\n",
      "index 41\n",
      "index 42\n",
      "index 43\n",
      "index 44\n",
      "index 45\n",
      "index 46\n",
      "index 47\n",
      "index 48\n",
      "index 49\n",
      "index 50\n",
      "index 51\n",
      "index 52\n",
      "index 53\n",
      "index 54\n",
      "index 55\n",
      "index 56\n",
      "index 57\n",
      "index 58\n",
      "index 59\n",
      "index 60\n",
      "index 61\n",
      "index 62\n",
      "index 63\n",
      "index 64\n",
      "index 65\n",
      "index 66\n",
      "index 67\n",
      "index 68\n",
      "index 69\n",
      "index 70\n",
      "index 71\n",
      "index 72\n",
      "index 73\n",
      "index 74\n",
      "index 75\n",
      "index 76\n",
      "index 77\n",
      "index 78\n",
      "index 79\n",
      "index 80\n",
      "index 81\n",
      "index 82\n",
      "index 83\n",
      "index 84\n",
      "index 85\n",
      "index 86\n",
      "index 87\n",
      "index 88\n",
      "index 89\n",
      "index 90\n",
      "index 91\n",
      "index 92\n",
      "index 93\n",
      "index 94\n",
      "index 95\n",
      "index 96\n",
      "index 97\n",
      "index 98\n",
      "index 99\n",
      "index 100\n",
      "index 101\n",
      "index 102\n",
      "index 103\n",
      "index 104\n",
      "index 105\n",
      "index 106\n",
      "index 107\n",
      "index 108\n",
      "index 109\n",
      "index 110\n",
      "index 111\n",
      "index 112\n",
      "index 113\n",
      "index 114\n",
      "index 115\n",
      "index 116\n",
      "index 117\n",
      "index 118\n",
      "index 119\n",
      "index 120\n",
      "index 121\n",
      "index 122\n",
      "index 123\n",
      "index 124\n",
      "index 125\n",
      "index 126\n",
      "index 127\n",
      "index 128\n",
      "index 129\n",
      "index 130\n",
      "index 131\n",
      "index 132\n",
      "index 133\n",
      "index 134\n",
      "index 135\n",
      "index 136\n",
      "index 137\n",
      "index 138\n",
      "index 139\n",
      "index 140\n",
      "index 141\n",
      "index 142\n",
      "index 143\n",
      "index 144\n",
      "index 145\n",
      "index 146\n",
      "index 147\n",
      "index 148\n",
      "index 149\n",
      "index 150\n",
      "index 151\n",
      "index 152\n",
      "index 153\n",
      "index 154\n",
      "index 155\n",
      "index 156\n",
      "index 157\n",
      "index 158\n",
      "index 159\n",
      "index 160\n",
      "index 161\n",
      "index 162\n",
      "index 163\n",
      "index 164\n",
      "index 165\n",
      "index 166\n",
      "index 167\n",
      "index 168\n",
      "index 169\n",
      "index 170\n",
      "index 171\n",
      "index 172\n",
      "index 173\n",
      "index 174\n",
      "index 175\n",
      "index 176\n",
      "index 177\n",
      "index 178\n",
      "index 179\n",
      "index 180\n",
      "index 181\n",
      "index 182\n",
      "index 183\n",
      "index 184\n",
      "index 185\n",
      "index 186\n",
      "index 187\n",
      "index 188\n",
      "index 189\n",
      "index 190\n",
      "index 191\n",
      "index 192\n",
      "index 193\n",
      "index 194\n",
      "index 195\n",
      "index 196\n",
      "index 197\n",
      "index 198\n",
      "index 199\n",
      "index 200\n",
      "index 201\n",
      "index 202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 203\n",
      "index 204\n",
      "index 205\n",
      "index 206\n",
      "index 207\n",
      "index 208\n",
      "index 209\n",
      "index 210\n",
      "index 211\n",
      "index 212\n",
      "index 213\n",
      "index 214\n",
      "index 215\n",
      "index 216\n",
      "index 217\n",
      "index 218\n",
      "index 219\n",
      "index 220\n",
      "index 221\n",
      "index 222\n",
      "index 223\n",
      "index 224\n",
      "index 225\n",
      "index 226\n",
      "index 227\n",
      "index 228\n",
      "index 229\n",
      "index 230\n",
      "index 231\n",
      "index 232\n",
      "index 233\n",
      "index 234\n",
      "index 235\n",
      "index 236\n",
      "index 237\n",
      "index 238\n",
      "index 239\n",
      "index 240\n",
      "index 241\n",
      "index 242\n",
      "index 243\n",
      "index 244\n",
      "index 245\n",
      "index 246\n",
      "index 247\n",
      "index 248\n",
      "index 249\n",
      "index 250\n",
      "index 251\n",
      "index 252\n",
      "index 253\n",
      "index 254\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.DataFrame()\n",
    "\n",
    "get_revised_probs = get_combined_probs\n",
    "\n",
    "for proj_name in ['openstack', 'qt']:\n",
    "    \n",
    "    print(proj_name, 'START')\n",
    "    for global_model_name in ['RF', 'LR']:\n",
    "        print(global_model_name, 'START')\n",
    "        \n",
    "        global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name, global_model_name)\n",
    "\n",
    "        x_train, y_train = prepare_data(proj_name, mode = 'train')\n",
    "\n",
    "        x_test, y_test = prepare_data(proj_name, mode = 'test')\n",
    "\n",
    "        y_test_flip = [False if val else True for val in y_test]\n",
    "\n",
    "        rq3_explanation_result = pd.DataFrame()\n",
    "\n",
    "        pyexp_guidance_result_list = []\n",
    "        lime_guidance_result_df = pd.DataFrame()\n",
    "\n",
    "        x_train_sd = x_train.std()\n",
    "        \n",
    "        for i in range(0,len(feature_df)):\n",
    "            \n",
    "            print('index', i)\n",
    "            tmp_df = pd.DataFrame()\n",
    "\n",
    "            X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "            row_index = str(X_explain.index[0])\n",
    "\n",
    "            exp_obj = pickle.load(open(pyExp_dir+proj_name+'_'+global_model_name+'_all_explainer_'+row_index+'.pkl','rb'))\n",
    "            py_exp = exp_obj['pyExplainer']\n",
    "            lime_exp = exp_obj['LIME']\n",
    "\n",
    "            # load local models\n",
    "            py_exp_local_model = py_exp['local_model']\n",
    "            lime_exp_local_model = lime_exp['local_model']\n",
    "\n",
    "            # generate explanations                \n",
    "            py_exp_the_best_defective_rule_str = get_g1_guidance(py_exp_local_model, X_explain)\n",
    "            lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "\n",
    "            # generate guidance\n",
    "            ## PyExplainer - PyFlip, PyG2, PyG4\n",
    "\n",
    "            pyFlip = flip_rule(py_exp_the_best_defective_rule_str)\n",
    "            pyG2, pyG4 = get_g2_g4_guidance(py_exp_local_model, X_explain)\n",
    "\n",
    "\n",
    "            tmp_df_i = get_revised_probs(X_explain, global_model, pyFlip, x_train_sd)\n",
    "            if len(tmp_df_i) > 0:\n",
    "                tmp_df_i['gtype'] = 'pyFlip'\n",
    "                tmp_df = tmp_df.append(tmp_df_i)\n",
    "\n",
    "            tmp_df_i = get_revised_probs(X_explain, global_model, pyG2, x_train_sd)\n",
    "            if len(tmp_df_i) > 0:\n",
    "                tmp_df_i['gtype'] = 'pyG2'\n",
    "                tmp_df = tmp_df.append(tmp_df_i)\n",
    "\n",
    "            tmp_df_i = get_revised_probs(X_explain, global_model, pyG4, x_train_sd)\n",
    "            if len(tmp_df_i) > 0:\n",
    "                tmp_df_i['gtype'] = 'pyG4'\n",
    "                tmp_df = tmp_df.append(tmp_df_i)\n",
    "\n",
    "\n",
    "            # LIME START\n",
    "            lime_guidance = flip_rule(lime_the_best_defective_rule_str)\n",
    "\n",
    "            tmp_df_i = get_revised_probs(X_explain, global_model, lime_guidance, x_train_sd)\n",
    "            if len(tmp_df_i) > 0:\n",
    "                tmp_df_i['gtype'] = 'LIMEFlip'\n",
    "                tmp_df = tmp_df.append(tmp_df_i)\n",
    "\n",
    "            tmp_df['commit_id'] = row_index\n",
    "            tmp_df['model'] = global_model_name\n",
    "            tmp_df['project'] = proj_name\n",
    "            all_df = all_df.append(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guidance</th>\n",
       "      <th>probOg</th>\n",
       "      <th>probRevisedPercent</th>\n",
       "      <th>probRevisedSD</th>\n",
       "      <th>gtype</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>model</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age &gt; 12.769999980926514</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>pyFlip</td>\n",
       "      <td>1e6973aee7137653c62dcef970b1e2527b50517d</td>\n",
       "      <td>RF</td>\n",
       "      <td>openstack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rtime &gt; -7.359999895095825</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>pyG2</td>\n",
       "      <td>1e6973aee7137653c62dcef970b1e2527b50517d</td>\n",
       "      <td>RF</td>\n",
       "      <td>openstack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asawr &gt; 0.004999999888241291</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.48</td>\n",
       "      <td>pyG4</td>\n",
       "      <td>1e6973aee7137653c62dcef970b1e2527b50517d</td>\n",
       "      <td>RF</td>\n",
       "      <td>openstack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la &lt;= 58.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.09</td>\n",
       "      <td>LIMEFlip</td>\n",
       "      <td>1e6973aee7137653c62dcef970b1e2527b50517d</td>\n",
       "      <td>RF</td>\n",
       "      <td>openstack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        guidance  probOg  probRevisedPercent  probRevisedSD  \\\n",
       "0      age > 12.769999980926514     0.57                0.11           0.09   \n",
       "0     rtime > -7.359999895095825    0.57                0.66           0.57   \n",
       "0   asawr > 0.004999999888241291    0.57                0.69           0.48   \n",
       "0                   la <= 58.00     0.57                0.22           0.09   \n",
       "\n",
       "      gtype                                 commit_id model    project  \n",
       "0    pyFlip  1e6973aee7137653c62dcef970b1e2527b50517d    RF  openstack  \n",
       "0      pyG2  1e6973aee7137653c62dcef970b1e2527b50517d    RF  openstack  \n",
       "0      pyG4  1e6973aee7137653c62dcef970b1e2527b50517d    RF  openstack  \n",
       "0  LIMEFlip  1e6973aee7137653c62dcef970b1e2527b50517d    RF  openstack  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guidance</th>\n",
       "      <th>probOg</th>\n",
       "      <th>probRevisedPercent</th>\n",
       "      <th>probRevisedSD</th>\n",
       "      <th>gtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la &lt;= 58.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.18</td>\n",
       "      <td>LIMEFlip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       guidance  probOg  probRevisedPercent  probRevisedSD     gtype\n",
       "0  la <= 58.00      0.6                0.73           0.18  LIMEFlip"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guidance</th>\n",
       "      <th>probOg</th>\n",
       "      <th>probRevisedPercent</th>\n",
       "      <th>probRevisedSD</th>\n",
       "      <th>gtype</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>model</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la &lt;= 3.4800000190734863 &amp; age &lt;= 0.5099999904...</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>pyFlip</td>\n",
       "      <td>1e6973aee7137653c62dcef970b1e2527b50517d</td>\n",
       "      <td>RF</td>\n",
       "      <td>openstack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nrev &gt; 1.0049999952316284 &amp; nrev &gt; 1.829999983...</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>pyG2</td>\n",
       "      <td>1e6973aee7137653c62dcef970b1e2527b50517d</td>\n",
       "      <td>RF</td>\n",
       "      <td>openstack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nrev &lt;= 2.100000023841858 &amp; asawr &gt; 0.00499999...</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>pyG4</td>\n",
       "      <td>1e6973aee7137653c62dcef970b1e2527b50517d</td>\n",
       "      <td>RF</td>\n",
       "      <td>openstack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la &lt;= 58.00</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>LIMEFlip</td>\n",
       "      <td>1e6973aee7137653c62dcef970b1e2527b50517d</td>\n",
       "      <td>RF</td>\n",
       "      <td>openstack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la &lt;= 102.78000259399414 &amp; age &gt; 3.23000001907...</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>pyFlip</td>\n",
       "      <td>5d0ccceb20780fdd3adf519d3f8e6b80b1844407</td>\n",
       "      <td>RF</td>\n",
       "      <td>openstack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la &lt;= 31.00</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.602519</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>LIMEFlip</td>\n",
       "      <td>979a0406f0013560efbdcc486b32ba93ce8c946f</td>\n",
       "      <td>LR</td>\n",
       "      <td>qt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age &gt; 30.4399995803833 &amp; nrev &lt;= 3.21000003814...</td>\n",
       "      <td>0.675246</td>\n",
       "      <td>0.473491</td>\n",
       "      <td>0.314228</td>\n",
       "      <td>pyFlip</td>\n",
       "      <td>337524714cad51934879d817564c5d58e6dbd0c0</td>\n",
       "      <td>LR</td>\n",
       "      <td>qt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rsawr &lt;= 0.11499999836087227 &amp; ndev &lt;= 6.83999...</td>\n",
       "      <td>0.675246</td>\n",
       "      <td>0.667617</td>\n",
       "      <td>0.633723</td>\n",
       "      <td>pyG2</td>\n",
       "      <td>337524714cad51934879d817564c5d58e6dbd0c0</td>\n",
       "      <td>LR</td>\n",
       "      <td>qt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hcmt &lt;= 10.579999923706055 &amp; age &gt; 16.57500076...</td>\n",
       "      <td>0.675246</td>\n",
       "      <td>0.542494</td>\n",
       "      <td>0.345836</td>\n",
       "      <td>pyG4</td>\n",
       "      <td>337524714cad51934879d817564c5d58e6dbd0c0</td>\n",
       "      <td>LR</td>\n",
       "      <td>qt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la &lt;= 31.00</td>\n",
       "      <td>0.675246</td>\n",
       "      <td>0.674682</td>\n",
       "      <td>0.673702</td>\n",
       "      <td>LIMEFlip</td>\n",
       "      <td>337524714cad51934879d817564c5d58e6dbd0c0</td>\n",
       "      <td>LR</td>\n",
       "      <td>qt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3632 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             guidance    probOg  \\\n",
       "0   la <= 3.4800000190734863 & age <= 0.5099999904...  0.570000   \n",
       "0   nrev > 1.0049999952316284 & nrev > 1.829999983...  0.570000   \n",
       "0   nrev <= 2.100000023841858 & asawr > 0.00499999...  0.570000   \n",
       "0                                        la <= 58.00   0.570000   \n",
       "0   la <= 102.78000259399414 & age > 3.23000001907...  0.580000   \n",
       "..                                                ...       ...   \n",
       "0                                        la <= 31.00   0.609164   \n",
       "0   age > 30.4399995803833 & nrev <= 3.21000003814...  0.675246   \n",
       "0   rsawr <= 0.11499999836087227 & ndev <= 6.83999...  0.675246   \n",
       "0   hcmt <= 10.579999923706055 & age > 16.57500076...  0.675246   \n",
       "0                                        la <= 31.00   0.675246   \n",
       "\n",
       "    probRevisedPercent  probRevisedSD     gtype  \\\n",
       "0             0.110000       0.090000    pyFlip   \n",
       "0             0.660000       0.570000      pyG2   \n",
       "0             0.690000       0.480000      pyG4   \n",
       "0             0.220000       0.090000  LIMEFlip   \n",
       "0             0.380000       0.270000    pyFlip   \n",
       "..                 ...            ...       ...   \n",
       "0             0.602519       0.601450  LIMEFlip   \n",
       "0             0.473491       0.314228    pyFlip   \n",
       "0             0.667617       0.633723      pyG2   \n",
       "0             0.542494       0.345836      pyG4   \n",
       "0             0.674682       0.673702  LIMEFlip   \n",
       "\n",
       "                                   commit_id model    project  \n",
       "0   1e6973aee7137653c62dcef970b1e2527b50517d    RF  openstack  \n",
       "0   1e6973aee7137653c62dcef970b1e2527b50517d    RF  openstack  \n",
       "0   1e6973aee7137653c62dcef970b1e2527b50517d    RF  openstack  \n",
       "0   1e6973aee7137653c62dcef970b1e2527b50517d    RF  openstack  \n",
       "0   5d0ccceb20780fdd3adf519d3f8e6b80b1844407    RF  openstack  \n",
       "..                                       ...   ...        ...  \n",
       "0   979a0406f0013560efbdcc486b32ba93ce8c946f    LR         qt  \n",
       "0   337524714cad51934879d817564c5d58e6dbd0c0    LR         qt  \n",
       "0   337524714cad51934879d817564c5d58e6dbd0c0    LR         qt  \n",
       "0   337524714cad51934879d817564c5d58e6dbd0c0    LR         qt  \n",
       "0   337524714cad51934879d817564c5d58e6dbd0c0    LR         qt  \n",
       "\n",
       "[3632 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(result_dir+'RQ4_combined_prob_from_guidance.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(result_dir+'RQ4_revised_prob_from_guidance.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_Oat",
   "language": "python",
   "name": "env_oat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
