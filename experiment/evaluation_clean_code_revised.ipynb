{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, time, re, sys, operator\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.metrics import auc, classification_report, roc_auc_score, f1_score, matthews_corrcoef, balanced_accuracy_score, r2_score , confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from my_util import *\n",
    "from lime.lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# from pyexplainer.pyexplainer_pyexplainer import PyExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from pyexplainer.pyexplainer_pyexplainer import PyExplainer\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './dataset/'\n",
    "result_dir = './eval_result/'\n",
    "dump_dataframe_dir = './dump_df/'\n",
    "pyExp_dir = './pyExplainer_obj/'\n",
    "other_object_dir = './other_object/'\n",
    "# proj_name = 'qt' # ['openstack','qt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_lime(proj_name):\n",
    "#     global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name)\n",
    "#     all_eval_result = pd.DataFrame()\n",
    "    \n",
    "#     for i in range(0,len(feature_df)):\n",
    "#         X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "#         row_index = str(X_explain.index[0])\n",
    "\n",
    "#         py_exp = pickle.load(open(pyExp_dir+proj_name+'_rulefit_crossoverinterpolation_'+row_index+'.pkl','rb'))\n",
    "#         lime_exp = pickle.load(open(pyExp_dir+proj_name+'_lime_'+row_index+'.pkl','rb'))\n",
    "\n",
    "#         # this data can be used for both local and global model\n",
    "#         py_exp_synthetic_data = py_exp['synthetic_data'].values\n",
    "#         # this data can be used with global model only\n",
    "#         lime_exp_synthetic_data = lime_exp['synthetic_instance_for_global_model']\n",
    "#         # this data can be used with local model only\n",
    "#         lime_exp_synthetic_data_local = lime_exp['synthetic_instance_for_lobal_model']\n",
    "        \n",
    "#         display(X_explain)\n",
    "#         display(lime_exp_synthetic_data[:5,:])\n",
    "#         display(lime_exp_synthetic_data_local[:5,:])\n",
    "        \n",
    "#         break\n",
    "        \n",
    "# test_lime('openstack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "flip_sign_dict = {\n",
    "    '<': '>=',\n",
    "    '>': '<=',\n",
    "    '=': '!=',\n",
    "    '>=': '<',\n",
    "    '<=': '>',\n",
    "    '!=': '=='\n",
    "}\n",
    "\n",
    "'''\n",
    "    input: rule (str)\n",
    "'''\n",
    "def flip_rule(rule):\n",
    "    rule = re.sub(r'\\b=\\b',' = ',rule) # for LIME\n",
    "#     rule = rule.replace('&','and') # for RuleFit\n",
    "    found_rule = re.findall('.* <=? [a-zA-Z]+ <=? .*', rule) # for LIME\n",
    "    ret = ''\n",
    "    \n",
    "    # for LIME that has condition like this: 0.53 < nref <= 0.83\n",
    "    if len(found_rule) > 0:\n",
    "        found_rule = found_rule[0]\n",
    "    \n",
    "        var_in_rule = re.findall('[a-zA-Z]+',found_rule)\n",
    "\n",
    "        var_in_rule = var_in_rule[0]\n",
    "        \n",
    "        splitted_rule = found_rule.split(var_in_rule)\n",
    "        splitted_rule[0] = splitted_rule[0] + var_in_rule # for left side\n",
    "        splitted_rule[1] = var_in_rule + splitted_rule[1] # for right side\n",
    "        combined_rule = splitted_rule[0] + ' or ' + splitted_rule[1]\n",
    "        ret = flip_rule(combined_rule)\n",
    "        \n",
    "    else:\n",
    "        for tok in rule.split():\n",
    "            if tok in flip_sign_dict:\n",
    "                ret = ret + flip_sign_dict[tok] + ' '\n",
    "            else:\n",
    "                ret = ret + tok + ' '\n",
    "    return ret\n",
    "\n",
    "def get_top_k_global_features(global_model, indep, top_k_global_feature_num = 5):\n",
    "    global_feature_df = pd.DataFrame()\n",
    "    global_feature_df['feature'] = indep\n",
    "    global_feature_df['importance'] = global_model.feature_importances_\n",
    "\n",
    "    global_feature_df = global_feature_df.sort_values(by='importance',ascending=False)\n",
    "\n",
    "    top_k_global_features = list(global_feature_df['feature'])[:top_k_global_feature_num]\n",
    "\n",
    "    return top_k_global_features\n",
    "    \n",
    "def sort_global_feature(global_model, indep):\n",
    "    global_feature_df = pd.DataFrame()\n",
    "    global_feature_df['feature'] = indep\n",
    "    global_feature_df['importance'] = global_model.feature_importances_\n",
    "\n",
    "    global_feature_df = global_feature_df.sort_values(by='importance',ascending=False)\n",
    "\n",
    "    sorted_global_features = list(global_feature_df['feature'])\n",
    "\n",
    "    return sorted_global_features\n",
    "\n",
    "def get_rule_str_of_rulefit(local_rulefit_model):\n",
    "    rule_df = local_rulefit_model.get_rules()\n",
    "#     print(rule_df)\n",
    "    top_k = 5\n",
    "    top_k_positive_rules = rule_df[(rule_df.coef > 0) & (rule_df.type=='rule')].sort_values(\"importance\", ascending=False).head(top_k)\n",
    "#     top_k_positive_rules = rule_df[(rule_df.coef > 0) & (rule_df.type=='rule')].sort_values(\"coef\", ascending=False).head(top_k)\n",
    "\n",
    "    the_best_defective_rule_str = list(top_k_positive_rules['rule'])[0]\n",
    "    \n",
    "    return the_best_defective_rule_str\n",
    "\n",
    "def get_rule_str_of_rulefit_new_version(local_rulefit_model):\n",
    "    rule_df = local_rulefit_model.get_rules()\n",
    "    rule_df =  rule_df[(rule_df.coef > 0) & (rule_df.type=='rule')].sort_values(\"importance\", ascending=False)\n",
    "    \n",
    "    rule_list = list(rule_df['rule'])\n",
    "    dup_feature_in_rule = [] # true or false...\n",
    "    \n",
    "    for r in rule_list:\n",
    "        var_in_rule = re.findall('[a-zA-Z]+', r)\n",
    "        var_count = Counter(var_in_rule)\n",
    "        max_count = max(list(var_count.values()))\n",
    "        \n",
    "        if max_count > 1:\n",
    "            dup_feature_in_rule.append(True)\n",
    "        else:\n",
    "            dup_feature_in_rule.append(False)\n",
    "           \n",
    "    if False not in set(dup_feature_in_rule):\n",
    "#         print('wtf')\n",
    "        rule_df = rule_df.head(5)\n",
    "        the_best_defective_rule_str = list(rule_df['rule'])[0]\n",
    "        \n",
    "    else:\n",
    "        rule_df['contain_dup_var'] = dup_feature_in_rule    \n",
    "        the_best_defective_rule_str = rule_df[rule_df['contain_dup_var']==False].iloc[0]['rule']\n",
    "    \n",
    "    return the_best_defective_rule_str\n",
    "\n",
    "def aggregate_list(l):\n",
    "    return np.mean(l), np.median(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_new_rule_from_rulefit(proj_name):\n",
    "#     global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name)\n",
    "#     all_eval_result = pd.DataFrame()\n",
    "    \n",
    "#     c = 0\n",
    "    \n",
    "# #     py_exp_all_rules = []\n",
    "# #     lime_all_rules = []\n",
    "#     py_exp_all_vars = []\n",
    "#     lime_all_vars = []\n",
    "    \n",
    "#     print('global feature feature importance ranking:')\n",
    "#     print(sort_global_feature(global_model, indep))\n",
    "#     for i in range(0,len(feature_df)):\n",
    "#         X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "#         row_index = str(X_explain.index[0])\n",
    "\n",
    "#         py_exp = pickle.load(open(pyExp_dir+proj_name+'_rulefit_crossoverinterpolation_'+row_index+'_20_rules.pkl','rb'))\n",
    "#         py_exp_local_model = py_exp['local_model']\n",
    "        \n",
    "#         lime_exp = pickle.load(open(pyExp_dir+proj_name+'_lime_'+row_index+'.pkl','rb'))\n",
    "        \n",
    "# #         py_exp_rule = get_rule_str_of_rulefit(py_exp_local_model)\n",
    "#         py_exp_rule_new = get_rule_str_of_rulefit_new_version(py_exp_local_model)\n",
    "#         lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "#         py_exp_pred = eval_rule(py_exp_rule_new, X_explain)[0]\n",
    "#         lime_pred = eval_rule(lime_the_best_defective_rule_str, X_explain)[0]\n",
    "\n",
    "#         if py_exp_pred == 1:\n",
    "#             py_exp_var_in_rule = list(set(re.findall('[a-zA-Z]+', py_exp_rule_new)))\n",
    "#             py_exp_all_vars.extend(py_exp_var_in_rule)\n",
    "#         if lime_pred == 1:\n",
    "#             lime_var_in_rule = list(set(re.findall('[a-zA-Z]+', lime_the_best_defective_rule_str)))\n",
    "#             lime_all_vars.extend(lime_var_in_rule)\n",
    "            \n",
    "# #         py_exp_all_rules.append(py_exp_rule_new)\n",
    "# #         lime_all_rules.append(lime_the_best_defective_rule_str)\n",
    "        \n",
    "# #         eval_result = eval_rule(lime_the_best_defective_rule_str, X_explain)\n",
    "\n",
    "# #         if eval_result[0]:\n",
    "# #             c =c+1\n",
    "\n",
    "    \n",
    "# #     print(len(set(py_exp_all_rules)))\n",
    "# #     print(len(set(lime_all_rules)))\n",
    "    \n",
    "#     print('pyExplainer var count')\n",
    "#     print(Counter(py_exp_all_vars))\n",
    "#     print('-'*100)\n",
    "#     print('LIME var count')\n",
    "#     print(Counter(lime_all_vars))\n",
    "    \n",
    "# print('openstack')\n",
    "# test_new_rule_from_rulefit('openstack')\n",
    "# print('*'*100)\n",
    "# print('qt')\n",
    "# test_new_rule_from_rulefit('qt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def is_in_top_k_global_features(top_k_global_features, the_best_defective_rule_str):\n",
    "    # remove numeric value\n",
    "    new_the_best_defective_rule_str = re.sub('\\d+','', the_best_defective_rule_str)\n",
    "\n",
    "    # remove special characters\n",
    "    new_the_best_defective_rule_str = re.sub('\\W+',' ',new_the_best_defective_rule_str)\n",
    "    splitted_rule = new_the_best_defective_rule_str.split()\n",
    "\n",
    "    local_feature_count = 0\n",
    "    \n",
    "    found_features = set(splitted_rule).intersection(top_k_global_features)\n",
    "    return list(found_features)\n",
    "\n",
    "# def eval_rule(rule, X_explain):\n",
    "#     var_in_rule = re.findall('[a-zA-Z]+',rule)\n",
    "#     rule = rule.replace('&','and') # just for rulefit\n",
    "#     rule = re.sub(r'\\b=\\b','==',rule)\n",
    "# #             rule = rule.replace('=','==')\n",
    "\n",
    "#     var_dict = {}\n",
    "\n",
    "#     for var in var_in_rule:\n",
    "#         var_dict[var] = float(X_explain[var])\n",
    "\n",
    "#     eval_result = eval(rule,var_dict)\n",
    "#     return eval_result\n",
    "\n",
    "        \n",
    "def prepare_data_for_testing(proj_name, global_model_name = 'RF'):\n",
    "    global_model_name = global_model_name.upper()\n",
    "    global_model = pickle.load(open(proj_name+'_'+global_model_name+'_global_model.pkl','rb'))\n",
    "\n",
    "    correctly_predict_df = pd.read_csv(dump_dataframe_dir+proj_name+'_'+global_model_name+'_correctly_predict_as_defective.csv')\n",
    "    correctly_predict_df = correctly_predict_df.set_index('commit_id')\n",
    "\n",
    "    dep = 'defect'\n",
    "    indep = correctly_predict_df.columns[:-3] # exclude the last 3 columns\n",
    "\n",
    "    feature_df = correctly_predict_df.loc[:, indep]\n",
    "    \n",
    "    return global_model, correctly_predict_df, indep, dep, feature_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_result_df(proj_name, global_model_name):\n",
    "    global_model_name = global_model_name.upper()\n",
    "    if global_model_name not in ['RF','LR']:\n",
    "        print('wrong global model name. the global model name must be RF or LR')\n",
    "        return\n",
    "    \n",
    "    prediction_df_dir = dump_dataframe_dir+proj_name+'_'+global_model_name+'_prediction_result.csv'\n",
    "    correctly_predict_df_dir = dump_dataframe_dir+proj_name+'_'+global_model_name+'_correctly_predict_as_defective.csv'\n",
    "    \n",
    "    if not os.path.exists(prediction_df_dir) or not os.path.exists(correctly_predict_df_dir):\n",
    "        global_model = pickle.load(open(proj_name+'_'+global_model_name+'_global_model.pkl','rb'))\n",
    "\n",
    "        pred = global_model.predict(x_test)\n",
    "        defective_prob = global_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "        prediction_df = x_test.copy()\n",
    "        prediction_df['pred'] = pred\n",
    "        prediction_df['defective_prob'] = defective_prob\n",
    "        prediction_df['defect'] = y_test\n",
    "\n",
    "    #     print('AUC is',roc_auc_score(y_test, defective_prob))\n",
    "        correctly_predict_df = prediction_df[(prediction_df['pred']==1) & (prediction_df['defect']==1)]\n",
    "\n",
    "        print('total correct prediction: {}'.format(str(len(correctly_predict_df))))\n",
    "\n",
    "        prediction_df.to_csv(prediction_df_dir)\n",
    "        correctly_predict_df.to_csv(correctly_predict_df_dir)\n",
    "    \n",
    "    else:\n",
    "        prediction_df = pd.read_csv(prediction_df_dir)\n",
    "        correctly_predict_df = pd.read_csv(correctly_predict_df_dir)\n",
    "        \n",
    "        prediction_df = prediction_df.set_index('commit_id')\n",
    "        correctly_predict_df = correctly_predict_df.set_index('commit_id')\n",
    "        print('total correct prediction: {}'.format(str(len(correctly_predict_df))))\n",
    "        \n",
    "    return prediction_df, correctly_predict_df\n",
    "\n",
    "def get_recall_at_k_percent_effort(percent_effort, result_df_arg, real_buggy_commits):\n",
    "    cum_LOC_k_percent = (percent_effort/100)*result_df_arg.iloc[-1]['cum_LOC']\n",
    "    buggy_line_k_percent =  result_df_arg[result_df_arg['cum_LOC'] <= cum_LOC_k_percent]\n",
    "    buggy_commit = buggy_line_k_percent[buggy_line_k_percent['defect']==True]\n",
    "    recall_k_percent_effort = len(buggy_commit)/float(len(real_buggy_commits))\n",
    "    \n",
    "    return recall_k_percent_effort\n",
    "\n",
    "def eval_global_model(proj_name, prediction_df):\n",
    "    ## since ld metric in openstack is removed by using autospearman, so this code is needed\n",
    "    ## but this is not problem for qt\n",
    "    \n",
    "    if proj_name == 'openstack':\n",
    "        x_train_original, x_test_original = prepare_data_all_metrics(proj_name, mode='all')\n",
    "        prediction_df = prediction_df.copy()\n",
    "#         print('add ld')\n",
    "#         display(x_test_original['ld'])\n",
    "        prediction_df['ld'] = list(x_test_original['ld'])\n",
    "        \n",
    "    prediction_df = prediction_df[['la','ld', 'pred', 'defective_prob' ,'defect']]\n",
    "    prediction_df['LOC'] = prediction_df['la']+prediction_df['ld']\n",
    "    \n",
    "    \n",
    "#     result_df['defect_density'] = result_df['defective_commit_prob']/result_df['LOC']\n",
    "    prediction_df['defect_density'] = prediction_df['defective_prob']/prediction_df['LOC']\n",
    "    prediction_df['actual_defect_density'] = prediction_df['defect']/prediction_df['LOC'] #defect density\n",
    "    \n",
    "    prediction_df = prediction_df.fillna(0)\n",
    "    prediction_df = prediction_df.replace(np.inf, 0)\n",
    "    \n",
    "    prediction_df = prediction_df.sort_values(by='defect_density',ascending=False)\n",
    "#     display(prediction_df.head())\n",
    "#     display(np.sum(prediction_df[prediction_df['la']==0]['defect']))\n",
    "    \n",
    "    actual_result_df = prediction_df.sort_values(by='actual_defect_density',ascending=False)\n",
    "    actual_worst_result_df = prediction_df.sort_values(by='actual_defect_density',ascending=True)\n",
    "\n",
    "    prediction_df['cum_LOC'] = prediction_df['LOC'].cumsum()\n",
    "    actual_result_df['cum_LOC'] = actual_result_df['LOC'].cumsum()\n",
    "    actual_worst_result_df['cum_LOC'] = actual_worst_result_df['LOC'].cumsum()\n",
    "\n",
    "    real_buggy_commits = prediction_df[prediction_df['defect'] == True]\n",
    "    \n",
    "#     display(prediction_df)\n",
    "#     display(real_buggy_commits)\n",
    "    \n",
    "    \n",
    "    AUC = roc_auc_score(prediction_df['defect'], prediction_df['defective_prob'])\n",
    "    f1 = f1_score(prediction_df['defect'], prediction_df['pred'])\n",
    "    \n",
    "    ifa = real_buggy_commits.iloc[0]['cum_LOC']\n",
    "#     print('ifa:',ifa)\n",
    "\n",
    "    cum_LOC_20_percent = 0.2*prediction_df.iloc[-1]['cum_LOC']\n",
    "    buggy_line_20_percent = prediction_df[prediction_df['cum_LOC'] <= cum_LOC_20_percent]\n",
    "    buggy_commit = buggy_line_20_percent[buggy_line_20_percent['defect']==True]\n",
    "    recall_20_percent_effort = len(buggy_commit)/float(len(real_buggy_commits))\n",
    "    \n",
    "    # find P_opt\n",
    "    percent_effort_list = []\n",
    "    predicted_recall_at_percent_effort_list = []\n",
    "    actual_recall_at_percent_effort_list = []\n",
    "    actual_worst_recall_at_percent_effort_list = []\n",
    "    \n",
    "    for percent_effort in np.arange(10,101,10):\n",
    "        predicted_recall_k_percent_effort = get_recall_at_k_percent_effort(percent_effort, prediction_df, real_buggy_commits)\n",
    "        actual_recall_k_percent_effort = get_recall_at_k_percent_effort(percent_effort, actual_result_df, real_buggy_commits)\n",
    "        actual_worst_recall_k_percent_effort = get_recall_at_k_percent_effort(percent_effort, actual_worst_result_df, real_buggy_commits)\n",
    "        \n",
    "        percent_effort_list.append(percent_effort/100)\n",
    "        \n",
    "        predicted_recall_at_percent_effort_list.append(predicted_recall_k_percent_effort)\n",
    "        actual_recall_at_percent_effort_list.append(actual_recall_k_percent_effort)\n",
    "        actual_worst_recall_at_percent_effort_list.append(actual_worst_recall_k_percent_effort)\n",
    "\n",
    "    p_opt = 1 - ((auc(percent_effort_list, actual_recall_at_percent_effort_list) - \n",
    "                 auc(percent_effort_list, predicted_recall_at_percent_effort_list)) /\n",
    "                (auc(percent_effort_list, actual_recall_at_percent_effort_list) -\n",
    "                auc(percent_effort_list, actual_worst_recall_at_percent_effort_list)))\n",
    "\n",
    "    print('AUC: {}, F1: {}, IFA: {}, Recall@20%Effort: {}, Popt: {}'.format(AUC,f1,ifa,recall_20_percent_effort,p_opt))\n",
    "    print(classification_report(prediction_df['defect'], prediction_df['pred']))\n",
    "#     display(cum_LOC_20_percent)\n",
    "#     display(buggy_line_20_percent)\n",
    "# #     display(cum_LOC_20_percent)\n",
    "#     display(buggy_commit)\n",
    "#     print(len(real_buggy_commits))\n",
    "#     display(recall_20_percent_effort)\n",
    "\n",
    "def get_global_model_evaluation_result(proj_name):\n",
    "    print('RF global model result')\n",
    "    rf_prediction_df, rf_correctly_predict_df = get_prediction_result_df(proj_name, 'rf')\n",
    "    eval_global_model(proj_name, rf_prediction_df)\n",
    "\n",
    "    print('-'*100)\n",
    "    \n",
    "    print('LR global model result')\n",
    "    lr_prediction_df, lr_correctly_predict_df = get_prediction_result_df(proj_name, 'lr')\n",
    "    eval_global_model(proj_name, lr_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def eval_rule(rule, x_df):\n",
    "    var_in_rule = list(set(re.findall('[a-zA-Z]+', rule)))\n",
    "    \n",
    "    rule = re.sub(r'\\b=\\b','==',rule)\n",
    "    if 'or' in var_in_rule:\n",
    "        var_in_rule.remove('or')\n",
    "        \n",
    "    rule = rule.replace('&','and')\n",
    "    \n",
    "    eval_result_list = []\n",
    "    \n",
    "#     print(rule)\n",
    "\n",
    "    for i in range(0,len(x_df)):\n",
    "        x = x_df.iloc[[i]]\n",
    "        col = x.columns\n",
    "        var_dict = {}\n",
    "\n",
    "        for var in var_in_rule:\n",
    "            var_dict[var] = float(x[var])\n",
    "\n",
    "#         print(var_dict)\n",
    "        \n",
    "        # if the rule does not satisfy clean commit, the truth value of the inversed rule when applied to clean commit is true\n",
    "        eval_result = eval(rule,var_dict)\n",
    "        eval_result_list.append(eval_result)\n",
    "        \n",
    "#         print(eval_result)\n",
    "#         break\n",
    "        \n",
    "    return eval_result_list\n",
    "\n",
    "# def summarize_rule_eval_result(py_exp_rule_str, lime_rule_str, x_df, ground_truth):\n",
    "# #     print('Rulefit')\n",
    "#     py_exp_all_eval_result = eval_rule(py_exp_rule_str, x_df)\n",
    "# #     print('LIME')\n",
    "#     lime_all_eval_result = eval_rule(lime_rule_str, x_df)\n",
    "\n",
    "# #     print(py_exp_rule_str)\n",
    "# #     print(lime_rule_str)\n",
    "    \n",
    "# #     tmp_df = x_df.copy()\n",
    "# #     tmp_df['ground_truth'] = ground_truth\n",
    "# #     tmp_df_clean = tmp_df[tmp_df['ground_truth']==False]\n",
    "    \n",
    "# #     display(tmp_df_clean)\n",
    "    \n",
    "#     py_exp_result_df = pd.DataFrame()\n",
    "#     py_exp_result_df['ground_truth'] = ground_truth\n",
    "#     py_exp_result_df['rule_result'] = py_exp_all_eval_result\n",
    "#     py_exp_result_df = py_exp_result_df[py_exp_result_df['rule_result']==True] # get commit that matches counter rule\n",
    "    \n",
    "# #     print('py_exp_result_df')\n",
    "# #     display(py_exp_result_df[py_exp_result_df['ground_truth']==False])\n",
    "# #     print(len(py_exp_result_df))\n",
    "#     # find ratio of clean commit\n",
    "#     py_exp_satisfy_rule_ratio = 100*(len(py_exp_result_df[py_exp_result_df['ground_truth']==False])/len(py_exp_result_df)) if len(py_exp_result_df) > 0 else 0\n",
    "    \n",
    "#     lime_result_df = pd.DataFrame()\n",
    "#     lime_result_df['ground_truth'] = ground_truth\n",
    "#     lime_result_df['rule_result'] = lime_all_eval_result\n",
    "    \n",
    "#     lime_result_df = lime_result_df[lime_result_df['rule_result']==True] # get commit that matches counter rule\n",
    "    \n",
    "# #     print(len(lime_result_df))\n",
    "    \n",
    "#     # find ratio of clean commit\n",
    "# #     print('lime_result_df')\n",
    "# #     display(lime_result_df[lime_result_df['ground_truth']==False])\n",
    "#     lime_satisfy_rule_ratio = 100*(len(lime_result_df[lime_result_df['ground_truth']==False])/len(lime_result_df))  if len(lime_result_df) > 0 else 0\n",
    "    \n",
    "# #     print(len(py_exp_result_df[py_exp_result_df['ground_truth']==False]))\n",
    "# #     print(len(lime_result_df[lime_result_df['ground_truth']==False]))\n",
    "    \n",
    "#     return py_exp_satisfy_rule_ratio, lime_satisfy_rule_ratio\n",
    "\n",
    "def summarize_rule_eval_result(rule_str, x_df):\n",
    "#     print('Rulefit')\n",
    "    all_eval_result = eval_rule(rule_str, x_df)\n",
    "    all_eval_result = np.array(all_eval_result).astype(bool)\n",
    "    \n",
    "#     result_df = pd.DataFrame()\n",
    "#     result_df['ground_truth'] = ground_truth\n",
    "#     result_df['rule_result'] = all_eval_result\n",
    "#     result_df = result_df[result_df['rule_result']==True] # get commit that matches counter rule\n",
    "    \n",
    "#     print('py_exp_result_df')\n",
    "#     display(py_exp_result_df[py_exp_result_df['ground_truth']==False])\n",
    "#     print(len(py_exp_result_df))\n",
    "    # find ratio of clean commit\n",
    "#     satisfy_rule_ratio = 100*(len(result_df[result_df['ground_truth']==False])/len(result_df)) if len(result_df) > 0 else 0\n",
    "\n",
    "    return all_eval_result\n",
    "\n",
    "'''\n",
    "    input:\n",
    "        local_model: local model of RuleFit\n",
    "        X_explain: an instance to be explained\n",
    "        \n",
    "    return:\n",
    "        g2_guide, g4_guide (string)\n",
    "        more info of g2/g4 guidance refers to SQAPlanner paper\n",
    "'''\n",
    "\n",
    "def get_g2_g4_guidance(local_model, X_explain):\n",
    "    rules = local_model.get_rules()\n",
    "    rules = rules[(rules['type']=='rule') & (rules['coef'] < 0) & (rules['importance'] > 0)]\n",
    "    rules_list = list(rules['rule'])\n",
    "    \n",
    "    rule_eval_result = []\n",
    "\n",
    "    for r in rules_list:\n",
    "        py_exp_pred = eval_rule(r, X_explain)[0]\n",
    "        rule_eval_result.append(py_exp_pred)\n",
    "        \n",
    "    rules['is_satisfy_instance'] = rule_eval_result\n",
    "    \n",
    "    g2_guide_df = rules[rules['is_satisfy_instance']==True]\n",
    "    g4_guide_df = rules[rules['is_satisfy_instance']==False]\n",
    "\n",
    "    g2_guide_df = g2_guide_df.sort_values(by='importance', ascending=False)\n",
    "    g4_guide_df = g4_guide_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    g2_guide = g2_guide_df.iloc[0]['rule']\n",
    "    g4_guide = g4_guide_df.iloc[0]['rule']\n",
    "    \n",
    "    return g2_guide, g4_guide\n",
    "\n",
    "def get_g1_guidance(local_model, X_explain):\n",
    "    rules = local_model.get_rules()\n",
    "    rules = rules[(rules['type']=='rule') & (rules['coef'] > 0) & (rules['importance'] > 0)]\n",
    "    rules_list = list(rules['rule'])\n",
    "    \n",
    "    rule_eval_result = []\n",
    "\n",
    "    for r in rules_list:\n",
    "        py_exp_pred = eval_rule(r, X_explain)[0]\n",
    "        rule_eval_result.append(py_exp_pred)\n",
    "        \n",
    "    rules['is_satisfy_instance'] = rule_eval_result\n",
    "    \n",
    "    g1_guide_df = rules[rules['is_satisfy_instance']==True]\n",
    "\n",
    "    g1_guide_df = g1_guide_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    g1_guide = g1_guide_df.iloc[0]['rule']\n",
    "    \n",
    "    return g1_guide\n",
    "def get_g1_guidancex(local_model, X_explain):\n",
    "    rules = local_model.get_rules()\n",
    "    rules = rules[(rules['type']=='rule') & (rules['coef'] > 0) & (rules['importance'] > 0)]\n",
    "    rules_list = list(rules['rule'])\n",
    "    \n",
    "    rule_eval_result = []\n",
    "\n",
    "    for r in rules_list:\n",
    "        py_exp_pred = eval_rule(r, X_explain)[0]\n",
    "        rule_eval_result.append(py_exp_pred)\n",
    "        \n",
    "    rules['is_satisfy_instance'] = rule_eval_result\n",
    "    \n",
    "    g1_guide_df = rules[rules['is_satisfy_instance']==True]\n",
    "\n",
    "    g1_guide_df = g1_guide_df.sort_values(by='coef', ascending=False)\n",
    "    \n",
    "    g1_guide = g1_guide_df.iloc[0]['rule']\n",
    "    \n",
    "    return g1_guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rule(proj_name):\n",
    "    global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_namez)\n",
    "    x_test, y_test = prepare_data(proj_name, mode = 'test')\n",
    "    \n",
    "    rq3_eval_result = pd.DataFrame() # for train data\n",
    "\n",
    "    py_exp_guide = []\n",
    "    lime_guide = []\n",
    "    \n",
    "    for i in range(0,len(feature_df)):\n",
    "        X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "        row_index = str(X_explain.index[0])\n",
    "\n",
    "        py_exp = pickle.load(open(pyExp_dir+proj_name+'_rulefit_crossoverinterpolation_'+row_index+'.pkl','rb'))\n",
    "        lime_exp = pickle.load(open(pyExp_dir+proj_name+'_lime_'+row_index+'.pkl','rb'))\n",
    "\n",
    "        py_exp_local_model = py_exp['local_model']\n",
    "        lime_exp_local_model = lime_exp['local_model']\n",
    "        \n",
    "        py_exp_the_best_defective_rule_str = get_rule_str_of_rulefit(py_exp_local_model)\n",
    "#         print(py_exp_the_best_defective_rule_str)\n",
    "        \n",
    "        total_cond_in_py_exp = len(py_exp_the_best_defective_rule_str.split('&'))\n",
    "        \n",
    "        lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "        py_exp_pred = eval_rule(py_exp_the_best_defective_rule_str, X_explain)[0]\n",
    "        lime_pred = eval_rule(lime_the_best_defective_rule_str, X_explain)[0]\n",
    "\n",
    "#         print(py_exp_pred, lime_pred)\n",
    "        if py_exp_pred:\n",
    "            py_exp_the_best_defective_rule_str = flip_rule(py_exp_the_best_defective_rule_str)\n",
    "            py_exp_guide.append(py_exp_the_best_defective_rule_str)\n",
    "\n",
    "        if lime_pred:\n",
    "            lime_the_best_defective_rule_str = flip_rule(lime_the_best_defective_rule_str)\n",
    "            lime_guide.append(lime_the_best_defective_rule_str)\n",
    "        \n",
    "    print(set(py_exp_guide))\n",
    "    print('total guidance:',len(set(py_exp_guide)))\n",
    "    print('-'*100)\n",
    "    print(set(lime_guide))\n",
    "    print('total guidance:',len(set(lime_guide)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_PyExplainer_guidance(proj_name, global_model, method_name, row_index, guidance, x_test, y_test_flip , flip=False):\n",
    "    guidance_list = guidance.split('&')\n",
    "    \n",
    "    guide_eval_result = pd.DataFrame()\n",
    "    \n",
    "    for condition in guidance_list:\n",
    "        if flip:\n",
    "            condition = flip_rule(condition)\n",
    "            \n",
    "        py_exp_guidance_eval = summarize_rule_eval_result(condition, x_test)\n",
    "\n",
    "        guide_prec = precision_score(y_test_flip, py_exp_guidance_eval)\n",
    "        guide_rec = recall_score(y_test_flip, py_exp_guidance_eval)\n",
    "\n",
    "        py_exp_serie_test = pd.Series(data=[proj_name, row_index, method_name, global_model,condition, guide_prec, guide_rec])\n",
    "        guide_eval_result = guide_eval_result.append(py_exp_serie_test,ignore_index=True)\n",
    "        \n",
    "    return guide_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rq3_eval(proj_name, global_model_name):\n",
    "    global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name, global_model_name)\n",
    "    x_test, y_test = prepare_data(proj_name, mode = 'test')\n",
    "    \n",
    "    y_test_flip = [False if val else True for val in y_test]\n",
    "    \n",
    "    rq3_explanation_result = pd.DataFrame()\n",
    "    \n",
    "    pyexp_guidance_result_list = []\n",
    "    lime_guidance_result_df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0,len(feature_df)):\n",
    "\n",
    "        X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "        row_index = str(X_explain.index[0])\n",
    "\n",
    "        exp_obj = pickle.load(open(pyExp_dir+proj_name+'_'+global_model_name+'_all_explainer_'+row_index+'.pkl','rb'))\n",
    "        py_exp = exp_obj['pyExplainer']\n",
    "        lime_exp = exp_obj['LIME']\n",
    "\n",
    "        # load local models\n",
    "        py_exp_local_model = py_exp['local_model']\n",
    "        lime_exp_local_model = lime_exp['local_model']\n",
    "        \n",
    "        # generate explanations                \n",
    "        py_exp_the_best_defective_rule_str = get_g1_guidance(py_exp_local_model, X_explain)\n",
    "        lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "        # check whether explanations apply to the instance to be explained\n",
    "        py_exp_pred = eval_rule(py_exp_the_best_defective_rule_str, X_explain)[0]\n",
    "        lime_pred = eval_rule(lime_the_best_defective_rule_str, X_explain)[0]\n",
    "\n",
    "        # split rule to get list of conditions\n",
    "        condition_list = py_exp_the_best_defective_rule_str.split('&')\n",
    "\n",
    "        # for explanations\n",
    "        for condition in condition_list:\n",
    "            condition = condition.strip()\n",
    "\n",
    "            py_exp_rule_eval = summarize_rule_eval_result(condition, x_test)\n",
    "\n",
    "            rule_prec = precision_score(y_test, py_exp_rule_eval)\n",
    "            rule_rec = recall_score(y_test, py_exp_rule_eval)\n",
    "\n",
    "            py_exp_serie_test = pd.Series(data=[proj_name, row_index, 'pyExplainer',global_model_name, condition, rule_prec, rule_rec, py_exp_pred])\n",
    "            rq3_explanation_result = rq3_explanation_result.append(py_exp_serie_test,ignore_index=True)\n",
    "\n",
    "        # for guidance\n",
    "        g2_guide, g4_guide = get_g2_g4_guidance(py_exp_local_model, X_explain)\n",
    "\n",
    "        flip_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpFlip', row_index,\n",
    "                                                           py_exp_the_best_defective_rule_str, x_test, y_test_flip, flip=True)\n",
    "        g2_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpG2', row_index,\n",
    "                                                           g2_guide, x_test, y_test_flip, flip=False)\n",
    "        g4_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpG4', row_index,\n",
    "                                                           g4_guide, x_test, y_test_flip, flip=False)\n",
    "\n",
    "        pyexp_guidance_result_list.append(flip_guide_eval_result)\n",
    "        pyexp_guidance_result_list.append(g2_guide_eval_result)\n",
    "        pyexp_guidance_result_list.append(g4_guide_eval_result)\n",
    "        # PyExp END\n",
    "        \n",
    "       \n",
    "        # LIME START\n",
    "        lime_rule_eval = summarize_rule_eval_result(lime_the_best_defective_rule_str, x_test)\n",
    "\n",
    "        rule_prec = precision_score(y_test, lime_rule_eval)\n",
    "        rule_rec = recall_score(y_test, lime_rule_eval)\n",
    "\n",
    "        lime_serie_test = pd.Series(data=[proj_name, row_index, 'LIME',global_model_name, lime_the_best_defective_rule_str, rule_prec, rule_rec, lime_pred])\n",
    "        rq3_explanation_result = rq3_explanation_result.append(lime_serie_test,ignore_index=True)\n",
    "\n",
    "        lime_guidance = flip_rule(lime_the_best_defective_rule_str)\n",
    "        lime_guidance_eval = summarize_rule_eval_result(lime_guidance, x_test)\n",
    "#             tn, fp, fn, tp = confusion_matrix(y_test, lime_rule_eval, labels=[1,0]).ravel()\n",
    "#             tp_rate = tp/(tp+fn)\n",
    "#             tn_rate = tn/(tn+fp)\n",
    "\n",
    "        guide_prec = precision_score(y_test_flip, lime_guidance_eval)\n",
    "        guide_rec = recall_score(y_test_flip, lime_guidance_eval)\n",
    "\n",
    "        lime_serie_test = pd.Series(data=[proj_name, row_index, 'LIME', global_model_name, lime_guidance, guide_prec, guide_rec])\n",
    "        lime_guidance_result_df = lime_guidance_result_df.append(lime_serie_test, ignore_index=True)\n",
    "            \n",
    "        print('finished {} from {} commits'.format(str(i+1),len(feature_df)))\n",
    "        \n",
    "        \n",
    "    pyexp_guidance_result_df = pd.concat(pyexp_guidance_result_list)\n",
    "    \n",
    "    rq3_guidance_result = pd.concat([pyexp_guidance_result_df, lime_guidance_result_df])\n",
    "    \n",
    "    \n",
    "    \n",
    "    rq3_explanation_result.columns = ['project','commit_id','method','global_model','explanation','precision','recall', 'isSatisfy']\n",
    "    rq3_guidance_result.columns = ['project','commit_id','method', 'global_model','guidance','precision','recall']\n",
    "\n",
    "    rq3_explanation_result.to_csv(result_dir+'RQ3_'+proj_name+'_'+global_model_name+'_explanation_eval_split_rulefit_condition.csv',index=False)\n",
    "    rq3_guidance_result.to_csv(result_dir+'RQ3_'+proj_name+'_'+global_model_name+'_guidance_eval_split_rulefit_condition.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'openstack'\n",
    "global_model_name = 'RF'\n",
    "\n",
    "global_model, correctly_predict_df, indep, dep, feature_df = prepare_data_for_testing(proj_name, global_model_name)\n",
    "x_test, y_test = prepare_data(proj_name, mode = 'test')\n",
    "\n",
    "y_test_flip = [False if val else True for val in y_test]\n",
    "\n",
    "rq3_explanation_result = pd.DataFrame()\n",
    "\n",
    "pyexp_guidance_result_list = []\n",
    "lime_guidance_result_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "row_index = str(X_explain.index[0])\n",
    "\n",
    "exp_obj = pickle.load(open(pyExp_dir+proj_name+'_'+global_model_name+'_all_explainer_'+row_index+'.pkl','rb'))\n",
    "py_exp = exp_obj['pyExplainer']\n",
    "lime_exp = exp_obj['LIME']\n",
    "\n",
    "py_exp_local_model = py_exp['local_model']\n",
    "lime_exp_local_model = lime_exp['local_model']\n",
    "\n",
    "py_exp_the_best_defective_rule_str = get_rule_str_of_rulefit(py_exp_local_model)\n",
    "lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "py_exp_pred = eval_rule(py_exp_the_best_defective_rule_str, X_explain)[0]\n",
    "lime_pred = eval_rule(lime_the_best_defective_rule_str, X_explain)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la > 58.00'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lime_exp['rule'].as_list()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_g1_guidance(local_model, X_explain):\n",
    "    rules = local_model.get_rules()\n",
    "    rules = rules[(rules['type']=='rule') & (rules['coef'] > 0) & (rules['importance'] > 0)]\n",
    "    rules_list = list(rules['rule'])\n",
    "    \n",
    "    rule_eval_result = []\n",
    "\n",
    "    for r in rules_list:\n",
    "        py_exp_pred = eval_rule(r, X_explain)[0]\n",
    "        rule_eval_result.append(py_exp_pred)\n",
    "        \n",
    "    rules['is_satisfy_instance'] = rule_eval_result\n",
    "    \n",
    "    g1_guide_df = rules[rules['is_satisfy_instance']==True]\n",
    "\n",
    "    g1_guide_df = g1_guide_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    g1_guide = g1_guide_df.iloc[0]['rule']\n",
    "    \n",
    "    return g1_guide\n",
    "\n",
    "g1_guide = get_g1_guidance(py_exp_local_model, X_explain)\n",
    "g1_guidex = get_g1_guidancex(py_exp_local_model, X_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = py_exp_local_model.get_rules()\n",
    "rules = rules[(rules['type']=='rule') & (rules['coef'] > 0) & (rules['importance'] > 0)]\n",
    "rules_list = list(rules['rule'])\n",
    "\n",
    "rule_eval_result = []\n",
    "\n",
    "for r in rules_list:\n",
    "    py_exp_pred = eval_rule(r, X_explain)[0]\n",
    "    rule_eval_result.append(py_exp_pred)\n",
    "\n",
    "rules['is_satisfy_instance'] = rule_eval_result\n",
    "\n",
    "g1_guide_df = rules[rules['is_satisfy_instance']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>type</th>\n",
       "      <th>coef</th>\n",
       "      <th>support</th>\n",
       "      <th>importance</th>\n",
       "      <th>is_satisfy_instance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>age &lt;= 12.769999980926514 &amp; age &gt; 0.5099999904...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.062858</td>\n",
       "      <td>0.550914</td>\n",
       "      <td>0.031266</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>ndev &lt;= 30.90499973297119 &amp; la &gt; 11.2899999618...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.056020</td>\n",
       "      <td>0.480418</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>age &gt; 0.5250000059604645 &amp; nrev &lt;= 2.985000014...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.057506</td>\n",
       "      <td>0.344648</td>\n",
       "      <td>0.027330</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>nd &lt;= 2.4600000381469727 &amp; ent &lt;= 0.9549999833...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.055320</td>\n",
       "      <td>0.590078</td>\n",
       "      <td>0.027207</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>nrev &gt; 1.0800000429153442 &amp; nrev &lt;= 2.97000002...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.315927</td>\n",
       "      <td>0.025897</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>age &lt;= 15.349999904632568 &amp; age &gt; 1.8000000119...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.543081</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>la &gt; 48.1200008392334 &amp; asawr &lt;= 0.00499999988...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.078329</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>rsawr &lt;= 0.13499999791383743</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.161880</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>asawr &lt;= 0.004999999888241291 &amp; la &gt; 10.860000...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.190601</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>ndev &gt; 0.8400000035762787 &amp; nrev &lt;= 6.65000009...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   rule  type      coef  \\\n",
       "278   age <= 12.769999980926514 & age > 0.5099999904...  rule  0.062858   \n",
       "1685  ndev <= 30.90499973297119 & la > 11.2899999618...  rule  0.056020   \n",
       "771   age > 0.5250000059604645 & nrev <= 2.985000014...  rule  0.057506   \n",
       "1200  nd <= 2.4600000381469727 & ent <= 0.9549999833...  rule  0.055320   \n",
       "902   nrev > 1.0800000429153442 & nrev <= 2.97000002...  rule  0.055707   \n",
       "...                                                 ...   ...       ...   \n",
       "1605  age <= 15.349999904632568 & age > 1.8000000119...  rule  0.000499   \n",
       "1352  la > 48.1200008392334 & asawr <= 0.00499999988...  rule  0.000808   \n",
       "646                        rsawr <= 0.13499999791383743  rule  0.000534   \n",
       "1030  asawr <= 0.004999999888241291 & la > 10.860000...  rule  0.000220   \n",
       "1428  ndev > 0.8400000035762787 & nrev <= 6.65000009...  rule  0.000895   \n",
       "\n",
       "       support  importance  is_satisfy_instance  \n",
       "278   0.550914    0.031266                 True  \n",
       "1685  0.480418    0.027988                 True  \n",
       "771   0.344648    0.027330                 True  \n",
       "1200  0.590078    0.027207                 True  \n",
       "902   0.315927    0.025897                 True  \n",
       "...        ...         ...                  ...  \n",
       "1605  0.543081    0.000248                 True  \n",
       "1352  0.078329    0.000217                 True  \n",
       "646   0.161880    0.000197                 True  \n",
       "1030  0.190601    0.000086                 True  \n",
       "1428  0.005222    0.000065                 True  \n",
       "\n",
       "[276 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_guide_df = g1_guide_df.sort_values(by='importance', ascending=False)\n",
    "g1_guide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>type</th>\n",
       "      <th>coef</th>\n",
       "      <th>support</th>\n",
       "      <th>importance</th>\n",
       "      <th>is_satisfy_instance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>ndev &lt;= 44.01500129699707 &amp; ndev &lt;= 49.2299995...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.898172</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>ndev &lt;= 42.08500099182129</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.898172</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>nd &gt; 1.5799999833106995 &amp; rtime &gt; -19.22000026...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.819843</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>nrev &lt;= 6.670000076293945 &amp; ent &lt;= 0.995000004...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.780679</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>la &gt; 3.1399999856948853 &amp; asawr &gt; -0.004999999...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.775457</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>la &gt; 210.02000427246094 &amp; app &gt; 2.995000004768...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>0.028721</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>la &gt; 179.98500061035156 &amp; app &gt; 3.975000023841858</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.026110</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>app &gt; 2.990000009536743 &amp; la &gt; 241.5</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.023011</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>la &gt; 109.65499877929688 &amp; rsawr &lt;= 0.100000001...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>ndev &gt; 0.8400000035762787 &amp; nrev &lt;= 6.65000009...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   rule  type      coef  \\\n",
       "796   ndev <= 44.01500129699707 & ndev <= 49.2299995...  rule  0.003537   \n",
       "973                           ndev <= 42.08500099182129  rule  0.013521   \n",
       "1704  nd > 1.5799999833106995 & rtime > -19.22000026...  rule  0.011864   \n",
       "754   nrev <= 6.670000076293945 & ent <= 0.995000004...  rule  0.000672   \n",
       "168   la > 3.1399999856948853 & asawr > -0.004999999...  rule  0.018433   \n",
       "...                                                 ...   ...       ...   \n",
       "273   la > 210.02000427246094 & app > 2.995000004768...  rule  0.020183   \n",
       "1672  la > 179.98500061035156 & app > 3.975000023841858  rule  0.002435   \n",
       "218                app > 2.990000009536743 & la > 241.5  rule  0.023011   \n",
       "1738  la > 109.65499877929688 & rsawr <= 0.100000001...  rule  0.002141   \n",
       "1428  ndev > 0.8400000035762787 & nrev <= 6.65000009...  rule  0.000895   \n",
       "\n",
       "       support  importance  is_satisfy_instance  \n",
       "796   0.898172    0.001070                 True  \n",
       "973   0.898172    0.004089                 True  \n",
       "1704  0.819843    0.004560                 True  \n",
       "754   0.780679    0.000278                 True  \n",
       "168   0.775457    0.007692                 True  \n",
       "...        ...         ...                  ...  \n",
       "273   0.028721    0.003371                 True  \n",
       "1672  0.026110    0.000388                 True  \n",
       "218   0.023499    0.003486                 True  \n",
       "1738  0.023499    0.000324                 True  \n",
       "1428  0.005222    0.000065                 True  \n",
       "\n",
       "[276 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_guide_df = g1_guide_df.sort_values(by='support', ascending=False)\n",
    "g1_guide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age <= 12.769999980926514 & age > 0.5099999904632568 & la > 3.4800000190734863'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age <= 12.769999980926514 & age > 0.5099999904632568 & la > 3.4800000190734863'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_guidex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3963"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>la</th>\n",
       "      <th>nd</th>\n",
       "      <th>ns</th>\n",
       "      <th>ent</th>\n",
       "      <th>nrev</th>\n",
       "      <th>rtime</th>\n",
       "      <th>self</th>\n",
       "      <th>ndev</th>\n",
       "      <th>age</th>\n",
       "      <th>app</th>\n",
       "      <th>rrexp</th>\n",
       "      <th>asawr</th>\n",
       "      <th>rsawr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5ce74eb5469b7f88f4448ccbc1afaa802a7cfdef</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.869722</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.045706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>0.113107</td>\n",
       "      <td>0.247377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878ac164a391e761c72c5fdcd12f0caf48c7d359</th>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.718116</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.979109</td>\n",
       "      <td>0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>13.035437</td>\n",
       "      <td>4.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>0.597853</td>\n",
       "      <td>0.296449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbab55c4da531e4695a6e3e577aaa4975f0fce79</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988699</td>\n",
       "      <td>6.0</td>\n",
       "      <td>81.107118</td>\n",
       "      <td>0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.302407</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.389047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2ba455e2d2bc41f4a80a08d5434b741ed715ef4</th>\n",
       "      <td>519</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.003877</td>\n",
       "      <td>0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>2.348328</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2086.0</td>\n",
       "      <td>0.122311</td>\n",
       "      <td>0.389511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9382ee659212285a203550cf60476dd146d27a29</th>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996276</td>\n",
       "      <td>3.0</td>\n",
       "      <td>105.237789</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.841916</td>\n",
       "      <td>3.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>0.820225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209c09a76f5e90aaa2899804686e6a513703d887</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.872523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1fdc4afa157887d45e2f326d7373a5b1e8ee7aeb</th>\n",
       "      <td>180</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.846758</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.130301</td>\n",
       "      <td>0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>0.501826</td>\n",
       "      <td>2.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.094218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaf5762be5d37cac022dc321b6400b9743a25303</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413817</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.489861</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.872975</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2299.0</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.352067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75c7f6a17a5bb78074518877bf73f0071b7758eb</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.908843</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.434687</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.840547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824051b1e5618388a17c88867a3037397bc96b7</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.858231</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75.987384</td>\n",
       "      <td>0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.044525</td>\n",
       "      <td>2.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>0.094461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3963 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           la  nd  ns       ent  nrev  \\\n",
       "commit_id                                                               \n",
       "5ce74eb5469b7f88f4448ccbc1afaa802a7cfdef   17   2   1  0.936667   7.0   \n",
       "878ac164a391e761c72c5fdcd12f0caf48c7d359   49   9   3  0.718116   5.0   \n",
       "bbab55c4da531e4695a6e3e577aaa4975f0fce79   16   2   1  0.988699   6.0   \n",
       "a2ba455e2d2bc41f4a80a08d5434b741ed715ef4  519  13   1  0.861772  24.0   \n",
       "9382ee659212285a203550cf60476dd146d27a29   89   2   1  0.996276   3.0   \n",
       "...                                       ...  ..  ..       ...   ...   \n",
       "209c09a76f5e90aaa2899804686e6a513703d887    2   1   1  0.000000   2.0   \n",
       "1fdc4afa157887d45e2f326d7373a5b1e8ee7aeb  180  39   1  0.846758  24.0   \n",
       "aaf5762be5d37cac022dc321b6400b9743a25303    4   2   1  0.413817   2.0   \n",
       "75c7f6a17a5bb78074518877bf73f0071b7758eb    0   1   1  0.000000   1.0   \n",
       "3824051b1e5618388a17c88867a3037397bc96b7   31   2   1  0.858231   7.0   \n",
       "\n",
       "                                               rtime  self   ndev        age  \\\n",
       "commit_id                                                                      \n",
       "5ce74eb5469b7f88f4448ccbc1afaa802a7cfdef   17.869722     0   38.0   0.045706   \n",
       "878ac164a391e761c72c5fdcd12f0caf48c7d359    9.979109     0  116.0  13.035437   \n",
       "bbab55c4da531e4695a6e3e577aaa4975f0fce79   81.107118     0  123.0   0.302407   \n",
       "a2ba455e2d2bc41f4a80a08d5434b741ed715ef4   16.003877     0  194.0   2.348328   \n",
       "9382ee659212285a203550cf60476dd146d27a29  105.237789     0    9.0  21.841916   \n",
       "...                                              ...   ...    ...        ...   \n",
       "209c09a76f5e90aaa2899804686e6a513703d887   20.872523     1    0.0   0.000000   \n",
       "1fdc4afa157887d45e2f326d7373a5b1e8ee7aeb   92.130301     0  411.0   0.501826   \n",
       "aaf5762be5d37cac022dc321b6400b9743a25303   18.489861     0   49.0  26.872975   \n",
       "75c7f6a17a5bb78074518877bf73f0071b7758eb   54.908843     0    4.0  65.434687   \n",
       "3824051b1e5618388a17c88867a3037397bc96b7   75.987384     0  205.0   0.044525   \n",
       "\n",
       "                                          app   rrexp     asawr     rsawr  \n",
       "commit_id                                                                  \n",
       "5ce74eb5469b7f88f4448ccbc1afaa802a7cfdef  1.0  1306.0  0.113107  0.247377  \n",
       "878ac164a391e761c72c5fdcd12f0caf48c7d359  4.0   373.0  0.597853  0.296449  \n",
       "bbab55c4da531e4695a6e3e577aaa4975f0fce79  7.0  2810.0  0.005334  0.389047  \n",
       "a2ba455e2d2bc41f4a80a08d5434b741ed715ef4  3.0  2086.0  0.122311  0.389511  \n",
       "9382ee659212285a203550cf60476dd146d27a29  3.0   632.0  0.235955  0.820225  \n",
       "...                                       ...     ...       ...       ...  \n",
       "209c09a76f5e90aaa2899804686e6a513703d887  0.0     0.0  0.000000  0.000000  \n",
       "1fdc4afa157887d45e2f326d7373a5b1e8ee7aeb  2.0   720.0  0.000268  0.094218  \n",
       "aaf5762be5d37cac022dc321b6400b9743a25303  4.0  2299.0  0.004550  0.352067  \n",
       "75c7f6a17a5bb78074518877bf73f0071b7758eb  8.0  1361.0  0.001139  0.840547  \n",
       "3824051b1e5618388a17c88867a3037397bc96b7  2.0   713.0  0.011105  0.094461  \n",
       "\n",
       "[3963 rows x 13 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commit_id\n",
       "5ce74eb5469b7f88f4448ccbc1afaa802a7cfdef    False\n",
       "878ac164a391e761c72c5fdcd12f0caf48c7d359    False\n",
       "bbab55c4da531e4695a6e3e577aaa4975f0fce79    False\n",
       "a2ba455e2d2bc41f4a80a08d5434b741ed715ef4    False\n",
       "9382ee659212285a203550cf60476dd146d27a29    False\n",
       "                                            ...  \n",
       "209c09a76f5e90aaa2899804686e6a513703d887    False\n",
       "1fdc4afa157887d45e2f326d7373a5b1e8ee7aeb    False\n",
       "aaf5762be5d37cac022dc321b6400b9743a25303    False\n",
       "75c7f6a17a5bb78074518877bf73f0071b7758eb    False\n",
       "3824051b1e5618388a17c88867a3037397bc96b7    False\n",
       "Name: defect, Length: 3963, dtype: bool"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>la</th>\n",
       "      <th>nd</th>\n",
       "      <th>ns</th>\n",
       "      <th>ent</th>\n",
       "      <th>nrev</th>\n",
       "      <th>rtime</th>\n",
       "      <th>self</th>\n",
       "      <th>ndev</th>\n",
       "      <th>age</th>\n",
       "      <th>app</th>\n",
       "      <th>rrexp</th>\n",
       "      <th>asawr</th>\n",
       "      <th>rsawr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10593c2eaf4eff4edb13b70f023acbbf743f129f</th>\n",
       "      <td>186</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757325</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.790243</td>\n",
       "      <td>0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2.372364</td>\n",
       "      <td>2.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>0.122838</td>\n",
       "      <td>0.093364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           la  nd  ns       ent  nrev  \\\n",
       "commit_id                                                               \n",
       "10593c2eaf4eff4edb13b70f023acbbf743f129f  186   9   1  0.757325  10.0   \n",
       "\n",
       "                                              rtime  self   ndev       age  \\\n",
       "commit_id                                                                    \n",
       "10593c2eaf4eff4edb13b70f023acbbf743f129f  19.790243     0  161.0  2.372364   \n",
       "\n",
       "                                          app  rrexp     asawr     rsawr  \n",
       "commit_id                                                                 \n",
       "10593c2eaf4eff4edb13b70f023acbbf743f129f  2.0  538.0  0.122838  0.093364  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.iloc[[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_exp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False\n",
      "finished 1 from 198 commits\n",
      "1 False\n",
      "finished 2 from 198 commits\n",
      "2 False\n",
      "finished 3 from 198 commits\n",
      "3 False\n",
      "finished 4 from 198 commits\n",
      "4 False\n",
      "finished 5 from 198 commits\n",
      "5 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0,len(feature_df)):\n",
    "    X_explain = feature_df.iloc[[i]]\n",
    "\n",
    "    row_index = str(X_explain.index[0])\n",
    "\n",
    "    exp_obj = pickle.load(open(pyExp_dir+proj_name+'_'+global_model_name+'_all_explainer_'+row_index+'.pkl','rb'))\n",
    "    py_exp = exp_obj['pyExplainer']\n",
    "    lime_exp = exp_obj['LIME']\n",
    "\n",
    "    py_exp_local_model = py_exp['local_model']\n",
    "    lime_exp_local_model = lime_exp['local_model']\n",
    "\n",
    "    py_exp_the_best_defective_rule_str = get_rule_str_of_rulefit(py_exp_local_model)\n",
    "    lime_the_best_defective_rule_str = lime_exp['rule'].as_list()[0][0]\n",
    "\n",
    "    py_exp_pred = eval_rule(py_exp_the_best_defective_rule_str, X_explain)[0]\n",
    "    lime_pred = eval_rule(lime_the_best_defective_rule_str, X_explain)[0]\n",
    "    \n",
    "    print(i, py_exp_pred)\n",
    "    if py_exp_pred:\n",
    "\n",
    "        condition_list = py_exp_the_best_defective_rule_str.split('&')\n",
    "\n",
    "        # for explanation\n",
    "        for condition in condition_list:\n",
    "            condition = condition.strip()\n",
    "\n",
    "            py_exp_rule_eval = summarize_rule_eval_result(condition, x_test)\n",
    "\n",
    "            rule_prec = precision_score(y_test, py_exp_rule_eval)\n",
    "            rule_rec = recall_score(y_test, py_exp_rule_eval)\n",
    "\n",
    "            py_exp_serie_test = pd.Series(data=[proj_name, row_index, 'pyExplainer',global_model_name, condition, rule_prec, rule_rec])\n",
    "            rq3_explanation_result = rq3_explanation_result.append(py_exp_serie_test,ignore_index=True)\n",
    "\n",
    "        # for guidance\n",
    "        g2_guide, g4_guide = get_g2_g4_guidance(py_exp_local_model, X_explain)\n",
    "\n",
    "        flip_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpFlip', row_index,\n",
    "                                                           py_exp_the_best_defective_rule_str, x_test, y_test_flip, flip=True)\n",
    "        g2_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpG2', row_index,\n",
    "                                                           g2_guide, x_test, y_test_flip, flip=False)\n",
    "        g4_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpG4', row_index,\n",
    "                                                           g4_guide, x_test, y_test_flip, flip=False)\n",
    "\n",
    "        pyexp_guidance_result_list.append(flip_guide_eval_result)\n",
    "        pyexp_guidance_result_list.append(g2_guide_eval_result)\n",
    "        pyexp_guidance_result_list.append(g4_guide_eval_result)\n",
    "\n",
    "        break\n",
    "    \n",
    "    if i == 5:\n",
    "        break\n",
    "    if lime_pred:\n",
    "        lime_rule_eval = summarize_rule_eval_result(lime_the_best_defective_rule_str, x_test)\n",
    "\n",
    "        rule_prec = precision_score(y_test, lime_rule_eval)\n",
    "        rule_rec = recall_score(y_test, lime_rule_eval)\n",
    "\n",
    "        lime_serie_test = pd.Series(data=[proj_name, row_index, 'LIME',global_model_name, lime_the_best_defective_rule_str, rule_prec, rule_rec])\n",
    "        rq3_explanation_result = rq3_explanation_result.append(lime_serie_test,ignore_index=True)\n",
    "\n",
    "        lime_guidance = flip_rule(lime_the_best_defective_rule_str)\n",
    "        lime_guidance_eval = summarize_rule_eval_result(lime_guidance, x_test)\n",
    "#             tn, fp, fn, tp = confusion_matrix(y_test, lime_rule_eval, labels=[1,0]).ravel()\n",
    "#             tp_rate = tp/(tp+fn)\n",
    "#             tn_rate = tn/(tn+fp)\n",
    "\n",
    "        guide_prec = precision_score(y_test_flip, lime_guidance_eval)\n",
    "        guide_rec = recall_score(y_test_flip, lime_guidance_eval)\n",
    "\n",
    "        lime_serie_test = pd.Series(data=[proj_name, row_index, 'LIME', global_model_name, lime_guidance, guide_prec, guide_rec])\n",
    "        lime_guidance_result_df = lime_guidance_result_df.append(lime_serie_test, ignore_index=True)\n",
    "\n",
    "    print('finished {} from {} commits'.format(str(i+1),len(feature_df)))\n",
    "\n",
    "\n",
    "# pyexp_guidance_result_df = pd.concat(pyexp_guidance_result_list)\n",
    "\n",
    "# rq3_guidance_result = pd.concat([pyexp_guidance_result_df, lime_guidance_result_df])\n",
    "\n",
    "\n",
    "\n",
    "# rq3_explanation_result.columns = ['project','commit_id','method','global_model','explanation','precision','recall']\n",
    "# rq3_guidance_result.columns = ['project','commit_id','method', 'global_model','guidance','precision','recall']\n",
    "\n",
    "# rq3_explanation_result.to_csv(result_dir+'RQ3_'+proj_name+'_'+global_model_name+'_explanation_eval_split_rulefit_condition.csv',index=False)\n",
    "# rq3_guidance_result.to_csv(result_dir+'RQ3_'+proj_name+'_'+global_model_name+'_guidance_eval_split_rulefit_condition.csv',index=False)\n",
    "\n",
    "\n",
    "    #         break\n",
    "        \n",
    "#     rq3_eval_result.columns = ['project', 'commit id', 'method', 'explanation','guidance', 'explantion_precision','explantion_recall', \n",
    "#                               'guidance_precision','guidance_recall', 'explanation_true_negative', 'explanation_false_positive',\n",
    "#                               'explanation_false_negative','explanation_true_positive']\n",
    "    \n",
    "#     rq3_eval_result.to_csv(result_dir+'RQ3_'+proj_name+'_'+global_model_name+'_split_rulefit_condition.csv',index=False)\n",
    "#     print('finished RQ3 of',proj_name)\n",
    "    \n",
    "#     display(rq3_eval_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rq3_eval('openstack','RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openstack\n",
      "finished 1 from 198 commits\n",
      "finished 2 from 198 commits\n",
      "finished 3 from 198 commits\n",
      "finished 4 from 198 commits\n",
      "finished 5 from 198 commits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 6 from 198 commits\n",
      "finished 7 from 198 commits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8a52646757aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openstack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrq3_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openstack'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finished in'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'secs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-fbedfc2b1887>\u001b[0m in \u001b[0;36mrq3_eval\u001b[0;34m(proj_name, global_model_name)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mcondition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mpy_exp_rule_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_rule_eval_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mrule_prec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_exp_rule_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-cecffb0f841c>\u001b[0m in \u001b[0;36msummarize_rule_eval_result\u001b[0;34m(rule_str, x_df)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize_rule_eval_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m#     print('Rulefit')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mall_eval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mall_eval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_eval_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-cecffb0f841c>\u001b[0m in \u001b[0;36meval_rule\u001b[0;34m(rule, x_df)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# if the rule does not satisfy clean commit, the truth value of the inversed rule when applied to clean commit is true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0meval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0meval_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print('openstack')\n",
    "rq3_eval('openstack','RF')\n",
    "end = time.time()\n",
    "print('finished in',str(end-start), 'secs')\n",
    "\n",
    "start = time.time()\n",
    "print('qt')\n",
    "rq3_eval('qt','RF')\n",
    "end = time.time()\n",
    "print('finished in',str(end-start), 'secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openstack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4ef43df39d91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openstack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrq3_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openstack'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finished in'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'secs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-fbedfc2b1887>\u001b[0m in \u001b[0;36mrq3_eval\u001b[0;34m(proj_name, global_model_name)\u001b[0m\n\u001b[1;32m     51\u001b[0m             g2_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpG2', row_index,\n\u001b[1;32m     52\u001b[0m                                                                g2_guide, x_test, y_test_flip, flip=False)\n\u001b[0;32m---> 53\u001b[0;31m             g4_guide_eval_result = eval_PyExplainer_guidance(proj_name, global_model_name,'PyExpG4', row_index,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                                                g4_guide, x_test, y_test_flip, flip=False)\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-aff127bf11b0>\u001b[0m in \u001b[0;36meval_PyExplainer_guidance\u001b[0;34m(proj_name, global_model, method_name, row_index, guidance, x_test, y_test_flip, flip)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcondition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflip_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpy_exp_guidance_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_rule_eval_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mguide_prec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_flip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_exp_guidance_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-cecffb0f841c>\u001b[0m in \u001b[0;36msummarize_rule_eval_result\u001b[0;34m(rule_str, x_df)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize_rule_eval_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m#     print('Rulefit')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mall_eval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mall_eval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_eval_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-cecffb0f841c>\u001b[0m in \u001b[0;36meval_rule\u001b[0;34m(rule, x_df)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_in_rule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mvar_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         print(var_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m         \u001b[0;31m# Do we have a slicer (on rows)?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3792\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3793\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3794\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \"\"\"\n\u001b[0;32m-> 1002\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mblknos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# Note: these can be altered by other BlockManager methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_blknos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_blklocs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print('openstack')\n",
    "rq3_eval('openstack','LR')\n",
    "end = time.time()\n",
    "print('finished in',str(end-start), 'secs')\n",
    "\n",
    "start = time.time()\n",
    "print('qt')\n",
    "rq3_eval('qt','LR')\n",
    "end = time.time()\n",
    "print('finished in',str(end-start), 'secs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_Oat",
   "language": "python",
   "name": "env_oat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
