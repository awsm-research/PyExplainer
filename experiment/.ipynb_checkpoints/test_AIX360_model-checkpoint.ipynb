{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from pyexplainer.pyexplainer_pyexplainer import PyExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, pickle, time\n",
    "# from datetime import datetime\n",
    "\n",
    "from my_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data_path = './dataset/'\n",
    "result_dir = './eval_result/'\n",
    "dump_dataframe_dir = './dump_df/'\n",
    "pyExp_dir = './pyExplainer_obj/'\n",
    "other_object_dir = './other_object/'\n",
    "proj_name = 'openstack' # ['openstack','qt']\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "    \n",
    "if not os.path.exists(dump_dataframe_dir):\n",
    "    os.makedirs(dump_dataframe_dir)\n",
    "    \n",
    "if not os.path.exists(pyExp_dir):\n",
    "    os.makedirs(pyExp_dir)\n",
    "    \n",
    "if not os.path.exists(other_object_dir):\n",
    "    os.makedirs(other_object_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_data(proj_name, mode = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['la', 'ld', 'nf', 'nd', 'ns', 'ent', 'nrev', 'rtime', 'hcmt', 'self', 'ndev', 'age', 'nuc', 'app', 'aexp', 'rexp', 'arexp', 'rrexp', 'asexp', 'rsexp', 'asawr', 'rsawr']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# # print(y_train)\n",
    "# for col in x_test.columns:\n",
    "#     print(col,len(x_test[col].unique()))\n",
    "\n",
    "col = list(x_test.columns)\n",
    "print(col)\n",
    "print(col.index('self'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train global model finished\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTE(k_neighbors=5, random_state=42, n_jobs=24)\n",
    "# enn = EditedNearestNeighbours(n_neighbors=5, n_jobs=24)\n",
    "# smt_tmk = SMOTETomek(smote = smt, random_state=0)\n",
    "# smt_enn = SMOTEENN(smote=smt, enn=enn, random_state=0)\n",
    "\n",
    "new_x_train, new_y_train = smt.fit_resample(x_train, y_train)\n",
    "\n",
    "def train_global_model(x_train,y_train):\n",
    "    global_model = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=24)\n",
    "    global_model.fit(x_train, y_train)\n",
    "\n",
    "    pickle.dump(global_model, open(proj_name+'_global_model.pkl','wb'))\n",
    "    print('train global model finished')\n",
    "    \n",
    "train_black_box = True\n",
    "\n",
    "if train_black_box:\n",
    "    train_global_model(new_x_train, new_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain correctly predicted defective commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = pickle.load(open(proj_name+'_global_model.pkl','rb'))\n",
    "# x_test, y_test = prepare_data(proj_name, mode = 'test')\n",
    "\n",
    "pred = global_model.predict(x_test)\n",
    "defective_prob = global_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "prediction_df = x_test.copy()\n",
    "prediction_df['pred'] = pred\n",
    "prediction_df['defective_prob'] = defective_prob\n",
    "prediction_df['defect'] = y_test\n",
    "\n",
    "correctly_predict_df = prediction_df[(prediction_df['pred']==1) & (prediction_df['defect']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "print(len(correctly_predict_df))\n",
    "prediction_df.to_csv(dump_dataframe_dir+proj_name+'_prediction_result.csv')\n",
    "correctly_predict_df.to_csv(dump_dataframe_dir+proj_name+'_correctly_predict_as_defective.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training local model\n",
    "\n",
    "Note: this step includes instance generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['la', 'ld', 'nf', 'nd', 'ns', 'ent', 'nrev', 'rtime', 'hcmt', 'self',\n",
      "       'ndev', 'age', 'nuc', 'app', 'aexp', 'rexp', 'arexp', 'rrexp', 'asexp',\n",
      "       'rsexp', 'asawr', 'rsawr', 'pred', 'defective_prob', 'defect'],\n",
      "      dtype='object')\n",
      "25\n",
      "Index(['la', 'ld', 'nf', 'nd', 'ns', 'ent', 'nrev', 'rtime', 'hcmt', 'self',\n",
      "       'ndev', 'age', 'nuc', 'app', 'aexp', 'rexp', 'arexp', 'rrexp', 'asexp',\n",
      "       'rsexp', 'asawr', 'rsawr'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "global_model = pickle.load(open(proj_name+'_global_model.pkl','rb'))\n",
    "\n",
    "load_prediction_from_file = True\n",
    "class_label = ['clean', 'defect']\n",
    "\n",
    "if load_prediction_from_file:\n",
    "    correctly_predict_df = pd.read_csv(dump_dataframe_dir+proj_name+'_correctly_predict_as_defective.csv')\n",
    "    correctly_predict_df = correctly_predict_df.set_index('Unnamed: 0')\n",
    "    \n",
    "dep = 'defect'\n",
    "indep = correctly_predict_df.columns[:22]\n",
    "\n",
    "print(correctly_predict_df.columns)\n",
    "print(len(correctly_predict_df.columns))\n",
    "print(indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(correctly_predict_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyExp = PyExplainer(x_train,\n",
    "            y_train,\n",
    "            indep,\n",
    "            dep,\n",
    "            class_label,\n",
    "            blackbox_model = global_model,\n",
    "            categorical_features = ['self'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = correctly_predict_df.loc[:, indep]\n",
    "test_label = correctly_predict_df.loc[:, dep]\n",
    "problem_index = [] # store index that cannot build pyExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyExplainer_obj(search_function, feature_df, test_label, explainer='LRR'):\n",
    "    problem_index = []\n",
    "    time_spent = []\n",
    "    \n",
    "    for i in range(0,len(feature_df)):\n",
    "        X_explain = feature_df.iloc[[i]]\n",
    "        y_explain = test_label.iloc[[i]]\n",
    "\n",
    "        row_index = str(X_explain.index[0])\n",
    "\n",
    "        start = time.time()\n",
    "        try:\n",
    "            pyExp_obj = pyExp.explain(X_explain,\n",
    "                                       y_explain,\n",
    "                                       search_function = search_function, \n",
    "                                       top_k = 1000,\n",
    "                                       max_rules=2000, \n",
    "                                       max_iter =None, \n",
    "                                       cv=5,\n",
    "                                       explainer=explainer,\n",
    "                                       debug = False)\n",
    "            synt_pred = pyExp_obj['synthetic_predictions']\n",
    "            \n",
    "            print('{}: found {} defect from total {}'.format(row_index, str(np.sum(synt_pred)), \n",
    "                                                         str(len(synt_pred))))\n",
    "            pickle.dump(pyExp_obj, open(pyExp_dir+proj_name+'_'+explainer+'_'+search_function+'_'+row_index+'.pkl','wb'))\n",
    "        \n",
    "        except Exception as e:\n",
    "            problem_index.append(row_index)\n",
    "            print('-'*100)\n",
    "            print(e)\n",
    "            print('found total {} problematic commit'.format(str(len(problem_index))))\n",
    "            print('-'*100)\n",
    "            \n",
    "#         break\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        time_spent.append(str(end-start))\n",
    "#     print(row_index)\n",
    "#     break\n",
    "    \n",
    "    \n",
    "    return time_spent, problem_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9703: found 63 defect from total 1000\n",
      "23348: found 31 defect from total 1000\n",
      "25135: found 175 defect from total 1000\n",
      "15814: found 207 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 1 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1650: found 208 defect from total 1000\n",
      "14991: found 104 defect from total 1000\n",
      "19600: found 254 defect from total 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868: found 1 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 2 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "4619: found 153 defect from total 1000\n",
      "16345: found 56 defect from total 1000\n",
      "3339: found 199 defect from total 1000\n",
      "3867: found 107 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 3 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "25262: found 154 defect from total 1000\n",
      "17550: found 211 defect from total 1000\n",
      "18685: found 185 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 4 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "3138: found 359 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 5 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "22437: found 49 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 6 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 7 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "16194: found 275 defect from total 1000\n",
      "22153: found 188 defect from total 1000\n",
      "9607: found 141 defect from total 1000\n",
      "16968: found 50 defect from total 1000\n",
      "15059: found 187 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 8 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "12374: found 116 defect from total 1000\n",
      "5745: found 266 defect from total 1000\n",
      "2428: found 73 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 9 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "17073: found 156 defect from total 1000\n",
      "23154: found 87 defect from total 1000\n",
      "26696: found 344 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 10 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2677: found 304 defect from total 1000\n",
      "2112: found 186 defect from total 1000\n",
      "1475: found 29 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 11 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "14989: found 48 defect from total 1000\n",
      "8041: found 78 defect from total 1000\n",
      "22368: found 213 defect from total 1000\n",
      "17152: found 87 defect from total 1000\n",
      "9016: found 327 defect from total 1000\n",
      "22508: found 30 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 12 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 13 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "26420: found 144 defect from total 1000\n",
      "25831: found 301 defect from total 1000\n",
      "20955: found 125 defect from total 1000\n",
      "10110: found 212 defect from total 1000\n",
      "25869: found 158 defect from total 1000\n",
      "7855: found 170 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 14 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "102: found 580 defect from total 1000\n",
      "21357: found 425 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 15 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "21810: found 46 defect from total 1000\n",
      "24792: found 87 defect from total 1000\n",
      "24223: found 31 defect from total 1000\n",
      "9134: found 104 defect from total 1000\n",
      "20823: found 531 defect from total 1000\n",
      "19984: found 370 defect from total 1000\n",
      "7452: found 104 defect from total 1000\n",
      "24748: found 380 defect from total 1000\n",
      "25242: found 379 defect from total 1000\n",
      "2696: found 58 defect from total 1000\n",
      "512: found 232 defect from total 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8188: found 1 defect from total 1000\n",
      "11408: found 550 defect from total 1000\n",
      "2536: found 423 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 16 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "18365: found 294 defect from total 1000\n",
      "19921: found 49 defect from total 1000\n",
      "12346: found 402 defect from total 1000\n",
      "15155: found 125 defect from total 1000\n",
      "4711: found 369 defect from total 1000\n",
      "11758: found 369 defect from total 1000\n",
      "3151: found 185 defect from total 1000\n",
      "25670: found 104 defect from total 1000\n",
      "6246: found 331 defect from total 1000\n",
      "11057: found 154 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 17 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "11527: found 104 defect from total 1000\n",
      "12067: found 356 defect from total 1000\n",
      "10055: found 343 defect from total 1000\n",
      "9308: found 28 defect from total 1000\n",
      "3034: found 331 defect from total 1000\n",
      "17418: found 136 defect from total 1000\n",
      "20978: found 58 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 18 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "9018: found 70 defect from total 1000\n",
      "13059: found 159 defect from total 1000\n",
      "9662: found 339 defect from total 1000\n",
      "23442: found 164 defect from total 1000\n",
      "5143: found 369 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 19 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "7017: found 10 defect from total 1000\n",
      "14312: found 419 defect from total 1000\n",
      "22350: found 145 defect from total 1000\n",
      "20260: found 32 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 20 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "17100: found 380 defect from total 1000\n",
      "16039: found 77 defect from total 1000\n",
      "3012: found 23 defect from total 1000\n",
      "2388: found 32 defect from total 1000\n",
      "23721: found 49 defect from total 1000\n",
      "2592: found 379 defect from total 1000\n",
      "17948: found 18 defect from total 1000\n",
      "15804: found 185 defect from total 1000\n",
      "19268: found 388 defect from total 1000\n",
      "17419: found 72 defect from total 1000\n",
      "8307: found 27 defect from total 1000\n",
      "8872: found 200 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 21 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "25030: found 22 defect from total 1000\n",
      "22016: found 367 defect from total 1000\n",
      "10962: found 364 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 22 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "15901: found 377 defect from total 1000\n",
      "13367: found 47 defect from total 1000\n",
      "19400: found 204 defect from total 1000\n",
      "25346: found 329 defect from total 1000\n",
      "3439: found 170 defect from total 1000\n",
      "19562: found 225 defect from total 1000\n",
      "18537: found 163 defect from total 1000\n",
      "19223: found 192 defect from total 1000\n",
      "20188: found 260 defect from total 1000\n",
      "11955: found 507 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 23 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "13540: found 279 defect from total 1000\n",
      "10739: found 221 defect from total 1000\n",
      "7576: found 106 defect from total 1000\n",
      "15421: found 154 defect from total 1000\n",
      "18993: found 195 defect from total 1000\n",
      "4949: found 652 defect from total 1000\n",
      "10673: found 379 defect from total 1000\n",
      "13847: found 264 defect from total 1000\n",
      "2443: found 375 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 24 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2290: found 360 defect from total 1000\n",
      "9469: found 212 defect from total 1000\n",
      "136: found 145 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 25 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "473: found 389 defect from total 1000\n",
      "7371: found 249 defect from total 1000\n",
      "6501: found 173 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 26 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 27 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "23766: found 357 defect from total 1000\n",
      "9442: found 293 defect from total 1000\n",
      "3847: found 148 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 28 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1697: found 162 defect from total 1000\n",
      "7578: found 41 defect from total 1000\n",
      "7533: found 49 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 29 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "21845: found 117 defect from total 1000\n",
      "18869: found 533 defect from total 1000\n",
      "5067: found 364 defect from total 1000\n",
      "3894: found 46 defect from total 1000\n",
      "14299: found 161 defect from total 1000\n",
      "10721: found 11 defect from total 1000\n",
      "9970: found 137 defect from total 1000\n",
      "1274: found 293 defect from total 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20091: found 294 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 30 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "4053: found 420 defect from total 1000\n",
      "24864: found 173 defect from total 1000\n",
      "17036: found 421 defect from total 1000\n",
      "15545: found 5 defect from total 1000\n",
      "16203: found 161 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 31 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 32 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "4516: found 305 defect from total 1000\n",
      "26075: found 71 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 33 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "17896: found 350 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 34 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 35 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "20454: found 15 defect from total 1000\n",
      "3010: found 282 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 36 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "12784: found 343 defect from total 1000\n",
      "23180: found 55 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 37 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 38 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2360: found 98 defect from total 1000\n",
      "12078: found 339 defect from total 1000\n",
      "15498: found 158 defect from total 1000\n",
      "8955: found 407 defect from total 1000\n",
      "26093: found 443 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 39 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "14048: found 119 defect from total 1000\n",
      "6889: found 58 defect from total 1000\n",
      "19332: found 204 defect from total 1000\n",
      "15253: found 293 defect from total 1000\n",
      "9434: found 182 defect from total 1000\n",
      "22835: found 351 defect from total 1000\n",
      "4567: found 299 defect from total 1000\n",
      "1928: found 179 defect from total 1000\n",
      "7952: found 94 defect from total 1000\n",
      "2465: found 184 defect from total 1000\n",
      "24834: found 248 defect from total 1000\n",
      "21065: found 143 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 40 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "22968: found 199 defect from total 1000\n",
      "12622: found 242 defect from total 1000\n",
      "12311: found 144 defect from total 1000\n",
      "8017: found 186 defect from total 1000\n",
      "21292: found 104 defect from total 1000\n",
      "11341: found 126 defect from total 1000\n",
      "23680: found 230 defect from total 1000\n",
      "19402: found 315 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 41 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 42 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "3644: found 206 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 43 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2685: found 361 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 44 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "14083: found 78 defect from total 1000\n",
      "25279: found 107 defect from total 1000\n",
      "19408: found 257 defect from total 1000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
      "found total 45 problematic commit\n",
      "----------------------------------------------------------------------------------------------------\n",
      "20989: found 58 defect from total 1000\n"
     ]
    }
   ],
   "source": [
    "# time_spent_rand, problem_index_rand = create_pyExplainer_obj('randompertubation', feature_df, test_label,'LRR')\n",
    "# pickle.dump(time_spent_rand, open(other_object_dir+proj_name+'_train_time_LRR_randompertubation.pkl','wb'))\n",
    "# pickle.dump(problem_index_rand, open(other_object_dir+proj_name+'_problem_index_LRR_randompertubation.pkl','wb'))\n",
    "\n",
    "# time_spent_rand, problem_index_rand = create_pyExplainer_obj('randompertubation', feature_df, test_label,'rulefit')\n",
    "# pickle.dump(time_spent_rand, open(other_object_dir+proj_name+'_train_time_rulefit_randompertubation.pkl','wb'))\n",
    "# pickle.dump(problem_index_rand, open(other_object_dir+proj_name+'_problem_index_rulefit_randompertubation.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9703: found 1419 defect from total 2117\n",
      "23348: found 1129 defect from total 2240\n",
      "25135: found 1179 defect from total 2240\n",
      "15814: found 1182 defect from total 2137\n",
      "1826: found 1469 defect from total 2156\n",
      "1650: found 1265 defect from total 2240\n",
      "14991: found 1183 defect from total 2234\n",
      "19600: found 1343 defect from total 2163\n",
      "868: found 1153 defect from total 2200\n",
      "18392: found 1328 defect from total 2101\n",
      "4619: found 1252 defect from total 2153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16345: found 1135 defect from total 2240\n",
      "3339: found 1378 defect from total 2196\n",
      "3867: found 1194 defect from total 2240\n",
      "361: found 1342 defect from total 2160\n",
      "25262: found 1205 defect from total 2197\n",
      "17550: found 1140 defect from total 2240\n",
      "18685: found 1399 defect from total 2132\n",
      "10085: found 1279 defect from total 2208\n",
      "3138: found 919 defect from total 2238\n",
      "24429: found 1501 defect from total 2111\n",
      "22437: found 1209 defect from total 2240\n",
      "23962: found 1529 defect from total 2131\n",
      "3948: found 1533 defect from total 2129\n",
      "16194: found 1239 defect from total 2155\n",
      "22153: found 1547 defect from total 2106\n",
      "9607: found 1393 defect from total 2109\n",
      "16968: found 1161 defect from total 2240\n",
      "15059: found 1176 defect from total 2240\n",
      "19968: found 1455 defect from total 2101\n",
      "12374: found 1223 defect from total 2240\n",
      "5745: found 1277 defect from total 2223\n",
      "2428: found 1471 defect from total 2113\n",
      "3149: found 1282 defect from total 2240\n",
      "17073: found 931 defect from total 2240\n",
      "23154: found 1085 defect from total 2240\n",
      "26696: found 1364 defect from total 2234\n",
      "22828: found 1402 defect from total 2103\n",
      "2677: found 1056 defect from total 2240\n",
      "2112: found 1101 defect from total 2240\n",
      "1475: found 1058 defect from total 2240\n",
      "22667: found 1403 defect from total 2113\n",
      "14989: found 1285 defect from total 2152\n",
      "8041: found 1347 defect from total 2151\n",
      "22368: found 1256 defect from total 2240\n",
      "17152: found 1400 defect from total 2118\n",
      "9016: found 1152 defect from total 2181\n",
      "22508: found 1337 defect from total 2211\n",
      "6665: found 1357 defect from total 2142\n",
      "243: found 1297 defect from total 2143\n",
      "26420: found 1177 defect from total 2240\n",
      "25831: found 1374 defect from total 2208\n",
      "20955: found 934 defect from total 2240\n",
      "10110: found 1216 defect from total 2240\n",
      "25869: found 1286 defect from total 2215\n",
      "7855: found 1233 defect from total 2172\n",
      "13463: found 1260 defect from total 2240\n",
      "102: found 1300 defect from total 2131\n",
      "21357: found 1246 defect from total 2143\n",
      "21312: found 1317 defect from total 2225\n",
      "21810: found 1231 defect from total 2233\n",
      "24792: found 1299 defect from total 2240\n",
      "24223: found 1216 defect from total 2240\n",
      "9134: found 1351 defect from total 2213\n",
      "20823: found 1028 defect from total 2240\n",
      "19984: found 1520 defect from total 2158\n",
      "7452: found 1249 defect from total 2240\n",
      "24748: found 1535 defect from total 2135\n",
      "25242: found 1169 defect from total 2240\n",
      "2696: found 1203 defect from total 2240\n",
      "512: found 873 defect from total 2240\n",
      "8188: found 1057 defect from total 2240\n",
      "11408: found 1130 defect from total 2229\n",
      "2536: found 884 defect from total 2240\n",
      "1423: found 1461 defect from total 2145\n",
      "18365: found 1286 defect from total 2167\n",
      "19921: found 1117 defect from total 2240\n",
      "12346: found 1430 defect from total 2227\n",
      "15155: found 1282 defect from total 2240\n",
      "4711: found 1352 defect from total 2215\n",
      "11758: found 1127 defect from total 2240\n",
      "3151: found 1167 defect from total 2240\n",
      "25670: found 1205 defect from total 2240\n",
      "6246: found 1230 defect from total 2166\n",
      "11057: found 1011 defect from total 2240\n",
      "12387: found 1242 defect from total 2240\n",
      "11527: found 1310 defect from total 2240\n",
      "12067: found 1176 defect from total 2227\n",
      "10055: found 1129 defect from total 2240\n",
      "9308: found 1183 defect from total 2233\n",
      "3034: found 1093 defect from total 2190\n",
      "17418: found 1384 defect from total 2116\n",
      "20978: found 939 defect from total 2240\n",
      "12409: found 1266 defect from total 2240\n",
      "9018: found 1507 defect from total 2130\n",
      "13059: found 1175 defect from total 2240\n",
      "9662: found 1373 defect from total 2150\n",
      "23442: found 1538 defect from total 2187\n",
      "5143: found 1177 defect from total 2172\n",
      "3973: found 1194 defect from total 2240\n",
      "7017: found 1467 defect from total 2121\n",
      "14312: found 969 defect from total 2240\n",
      "22350: found 1112 defect from total 2240\n",
      "20260: found 1390 defect from total 2200\n",
      "8561: found 1503 defect from total 2143\n",
      "17100: found 1097 defect from total 2232\n",
      "16039: found 1322 defect from total 2103\n",
      "3012: found 1527 defect from total 2162\n",
      "2388: found 1369 defect from total 2095\n",
      "23721: found 976 defect from total 2240\n",
      "2592: found 890 defect from total 2240\n",
      "17948: found 1205 defect from total 2240\n",
      "15804: found 1191 defect from total 2240\n",
      "19268: found 1418 defect from total 2161\n",
      "17419: found 1287 defect from total 2172\n",
      "8307: found 1179 defect from total 2240\n",
      "8872: found 1358 defect from total 2166\n",
      "13601: found 1411 defect from total 2119\n",
      "25030: found 1107 defect from total 2240\n",
      "22016: found 1169 defect from total 2190\n",
      "10962: found 1177 defect from total 2182\n",
      "16945: found 1463 defect from total 2134\n",
      "15901: found 1171 defect from total 2168\n",
      "13367: found 1350 defect from total 2101\n",
      "19400: found 1071 defect from total 2240\n",
      "25346: found 1292 defect from total 2240\n",
      "3439: found 1249 defect from total 2199\n",
      "19562: found 982 defect from total 2240\n",
      "18537: found 982 defect from total 2240\n"
     ]
    }
   ],
   "source": [
    "# time_spent_ci, problem_index_ci = create_pyExplainer_obj('crossoverinterpolation', feature_df, test_label)\n",
    "# pickle.dump(time_spent_ci, open(other_object_dir+proj_name+'_train_time_LRR_crossoverinterpolation.pkl','wb'))\n",
    "# pickle.dump(problem_index_ci, open(other_object_dir+proj_name+'_problem_index_LRR_crossoverinterpolation.pkl','wb'))\n",
    "\n",
    "# time_spent_ci, problem_index_ci = create_pyExplainer_obj('crossoverinterpolation', feature_df, test_label,'rulefit')\n",
    "# pickle.dump(time_spent_ci, open(other_object_dir+proj_name+'_train_time_rulefit_crossoverinterpolation.pkl','wb'))\n",
    "# pickle.dump(problem_index_ci, open(other_object_dir+proj_name+'_problem_index_rulefit_crossoverinterpolation.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(feature_df)\n",
    "# for c in feature_df:\n",
    "#     print(c)\n",
    "\n",
    "# for k in range(0,1):\n",
    "#     print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test feature binarizer\n",
    "# from pyexplainer.features import *\n",
    "# fb = FeatureBinarizer(negations=True)\n",
    "# fb.fit(x_train)\n",
    "# display(fb.transform(feature_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# search_function='randompertubation'\n",
    "# i = 3\n",
    "\n",
    "# X_explain = feature_df.iloc[[i]]\n",
    "# y_explain = test_label.iloc[[i]]\n",
    "\n",
    "# row_index = str(X_explain.index[0])\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# pyExp_obj = pyExp.explain(X_explain,\n",
    "#                            y_explain,\n",
    "#                            search_function = search_function, \n",
    "#                            top_k = 1000,\n",
    "#                            max_rules=2000, \n",
    "#                            max_iter =None, \n",
    "#                            cv=5,\n",
    "#                            explainer='rulefit',\n",
    "#                            debug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['synthetic_data', 'synthetic_predictions', 'X_explain', 'y_explain', 'indep', 'dep', 'local_model', 'top_k_positive_rules', 'top_k_negative_rules'])\n"
     ]
    }
   ],
   "source": [
    "print(pyExp_obj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(pyExp_obj['synthetic_data_fb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "# local_model = pyExp_obj['local_model']\n",
    "# print(local_model.predict(X_explain.values))\n",
    "# print('------------------Explanation from local model-------------------------')\n",
    "# print(local_model.explain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(pyExp_obj['X_explain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(local_model.predict(pyExp_obj['X_explain_fb']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample code for RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_instances = pyExp_obj['synthetic_data']\n",
    "# sample_instance = pyExp_obj['X_explain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def agg_list(val):\n",
    "#     return np.mean(val), np.median(val), np.max(val)\n",
    "\n",
    "# cos_sim = cosine_similarity(sample_instance.values.reshape(1,-1), synthetic_instances.values)[0]\n",
    "# euclid_dist = euclidean_distances(sample_instance.values.reshape(1,-1), synthetic_instances.values)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample code for RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False] [0.06562197]\n"
     ]
    }
   ],
   "source": [
    "# '''get prediction from global model then compare with result obtained from model (but how to compare??)'''\n",
    "\n",
    "# local_model = pyExp_obj['local_model']\n",
    "# '''In case pyExp uses logistic rule regression'''\n",
    "# fb_sample_instance = pyExp.feature_binarizer.transform(sample_instance)\n",
    "# # print(pyExp.feature_binarizer.transform(sample_instance))\n",
    "# local_pred = local_model.predict(fb_sample_instance)\n",
    "# local_pred_prob = local_model.predict_proba(fb_sample_instance)\n",
    "\n",
    "# '''In case pyExp uses RuleFit'''\n",
    "# # local_pred = local_model.predict(sample_instance)\n",
    "# # local_pred_prob = local_model.predict_proba(sample_instance)\n",
    "\n",
    "# print(local_pred, local_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Prediction from local model-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rule coefficient\n",
      "0   (intercept)    0.926494\n",
      "1  nrev <= 1.00  -11.265911\n",
      "2    nd <= 1.00   -3.340535\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            rule coefficient\n",
      "0    (intercept)   -4.822969\n",
      "1   nrev <= 1.00  -21.790036\n",
      "2    ent <= 0.90    11.04842\n",
      "3  asawr <= 0.16    2.480303\n",
      "4    nuc <= 3.00    2.480303\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rule coefficient\n",
      "0   (intercept)   -9.127939\n",
      "1  nrev <= 2.00   12.185013\n",
      "2  nrev <= 1.00   -7.495421\n",
      "3   ent <= 0.63   -7.495421\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "there is only 1 class in the generated instances\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            rule coefficient\n",
      "0    (intercept)    0.721183\n",
      "1   nrev <= 1.00   -8.482928\n",
      "2  asawr <= 0.05   -7.399822\n",
      "----------------------------------------------------------------------------------------------------\n",
      "          rule coefficient\n",
      "0  (intercept)   -3.748032\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rule coefficient\n",
      "0   (intercept)   -9.149672\n",
      "1  nrev <= 2.00   14.773528\n",
      "2  nrev <= 1.00    -9.91744\n",
      "3   ent <= 0.00   -8.247625\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            rule coefficient\n",
      "0    (intercept)  -10.434791\n",
      "1   nrev <= 1.00  -15.862358\n",
      "2  asawr <= 0.09   15.725896\n",
      "----------------------------------------------------------------------------------------------------\n",
      "          rule coefficient\n",
      "0  (intercept)   -2.933625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "            rule coefficient\n",
      "0    (intercept)    1.111113\n",
      "1     ld <= 0.00  -11.000013\n",
      "2   nrev <= 1.00   -2.505401\n",
      "3  asawr <= 0.00   -0.249322\n",
      "4  asawr <= 0.00   -0.249322\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/oathaha/.conda/envs/env_oat/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "# test rulefit\n",
    "search_function='randompertubation'\n",
    "print('------------------Prediction from local model-------------------------')\n",
    "for i in [3,5,7,20,50,100,83,25,163,127]:\n",
    "    X_explain = feature_df.iloc[[i]]\n",
    "    y_explain = test_label.iloc[[i]]\n",
    "\n",
    "    row_index = str(X_explain.index[0])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    try:\n",
    "        pyExp_obj = pyExp.explain(X_explain,\n",
    "                                   y_explain,\n",
    "                                   search_function = search_function, \n",
    "                                   top_k = 1000,\n",
    "                                   max_rules=2000, \n",
    "                                   max_iter =None, \n",
    "                                   cv=5,\n",
    "                                   explainer='LRR',\n",
    "                                   debug = False)\n",
    "        end = time.time()\n",
    "#         print('time spent to train LRR:',str(end-start),'secs')\n",
    "        \n",
    "        local_model = pyExp_obj['local_model']\n",
    "        print(local_model.explain())\n",
    "        \n",
    "#         print(global_model.predict_proba(X_explain)[:,1], local_model.predict_proba(pyExp.scaler.transform(X_explain.values))[:,1])\n",
    "#         print(local_model.explain())\n",
    "        print('-'*100)\n",
    "    except:\n",
    "        print('-'*100)\n",
    "        print('there is only 1 class in the generated instances')\n",
    "        print('-'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Prediction from local model-------------------------\n",
      "[0.84] [0.96695341]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0.73] [0.49372837]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0.83] [0.99548978]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0.67] [0.93530316]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0.6] [0.94639136]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0.66] [0.94685406]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0.62] [0.77372941]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0.75] [0.91593334]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0.7] [0.66951567]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0.58] [0.82852018]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test rulefit\n",
    "search_function='crossoverinterpolation'\n",
    "print('------------------Prediction from local model-------------------------')\n",
    "for i in [3,5,7,20,50,100,83,25,163,127]:\n",
    "    X_explain = feature_df.iloc[[i]]\n",
    "    y_explain = test_label.iloc[[i]]\n",
    "\n",
    "    row_index = str(X_explain.index[0])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        pyExp_obj = pyExp.explain(X_explain,\n",
    "                                   y_explain,\n",
    "                                   search_function = search_function, \n",
    "                                   top_k = 1000,\n",
    "                                   max_rules=2000, \n",
    "                                   max_iter =None, \n",
    "                                   cv=5,\n",
    "                                   explainer='rulefit',\n",
    "                                   debug = False)\n",
    "        end = time.time()\n",
    "#         print('time spent to train LRR:',str(end-start),'secs')\n",
    "        \n",
    "        local_model = pyExp_obj['local_model']\n",
    "        \n",
    "        print(global_model.predict_proba(X_explain)[:,1], local_model.predict_proba(X_explain.values)[:,1])\n",
    "#         print(local_model.explain())\n",
    "        print('-'*100)\n",
    "    except:\n",
    "        print('-'*100)\n",
    "        print('there is only 1 class in the generated instances')\n",
    "        print('-'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent to train LRR: 1.4275202751159668 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time spent to train LRR: 1.738269329071045 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time spent to train LRR: 1.0873517990112305 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time spent to train LRR: 0.9002327919006348 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time spent to train LRR: 1.3496229648590088 secs\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3599\u001b[0m         \"\"\"\n\u001b[0;32m-> 3600\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3601\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3586\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   3587\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexers.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-73e92f53bfa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m83\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m163\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m127\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_explain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_explain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0;31m# re-raise with different error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "# sample LRR when used with random perturbation\n",
    "\n",
    "search_function='randompertubation'\n",
    "\n",
    "for i in [3,5,7,20,50,100,83,25,163,127]:\n",
    "    X_explain = feature_df.iloc[[i]]\n",
    "    y_explain = test_label.iloc[[i]]\n",
    "\n",
    "    row_index = str(X_explain.index[0])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        pyExp_obj = pyExp.explain(X_explain,\n",
    "                                   y_explain,\n",
    "                                   search_function = search_function, \n",
    "                                   top_k = 1000,\n",
    "                                   max_rules=2000, \n",
    "                                   max_iter =None, \n",
    "                                   cv=5,\n",
    "                                   explainer='LRR',\n",
    "                                   debug = False)\n",
    "        end = time.time()\n",
    "        print('time spent to train LRR:',str(end-start),'secs')\n",
    "\n",
    "#         local_model = pyExp_obj['local_model']\n",
    "#         print('------------------Explanation from local model-------------------------')\n",
    "#         print(local_model.explain())\n",
    "        print('-'*100)\n",
    "    except:\n",
    "        print('-'*100)\n",
    "        print('there is only 1 class in the generated instances')\n",
    "        print('-'*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent to train LRR: 28.87514853477478 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time spent to train LRR: 26.213839769363403 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time spent to train LRR: 25.021041870117188 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time spent to train LRR: 29.421844244003296 secs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time spent to train LRR: 26.97343945503235 secs\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3599\u001b[0m         \"\"\"\n\u001b[0;32m-> 3600\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3601\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3586\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   3587\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexers.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b3ee45065751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m83\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m163\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m127\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_explain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_explain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/env_oat/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0;31m# re-raise with different error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "# sample LRR when used with crossover interpolation\n",
    "\n",
    "search_function='crossoverinterpolation'\n",
    "\n",
    "for i in [3,5,7,20,50,100,83,25,163,127]:\n",
    "    X_explain = feature_df.iloc[[i]]\n",
    "    y_explain = test_label.iloc[[i]]\n",
    "\n",
    "    row_index = str(X_explain.index[0])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    start = time.time()\n",
    "    pyExp_obj = pyExp.explain(X_explain,\n",
    "                               y_explain,\n",
    "                               search_function = search_function, \n",
    "                               top_k = 1000,\n",
    "                               max_rules=2000, \n",
    "                               max_iter =None, \n",
    "                               cv=5,\n",
    "                               explainer='LRR',\n",
    "                               debug = False)\n",
    "    end = time.time()\n",
    "    print('time spent to train LRR:',str(end-start),'secs')\n",
    "    \n",
    "#     local_model = pyExp_obj['local_model']\n",
    "#     print('------------------Explanation from local model-------------------------')\n",
    "#     print(local_model.explain())\n",
    "    print('-'*100)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['synthetic_data', 'synthetic_predictions', 'X_explain', 'y_explain', 'X_explain_fb', 'indep', 'dep', 'local_model'])\n"
     ]
    }
   ],
   "source": [
    "print(pyExp_obj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(pyExp_obj['synthetic_data'].columns)\n",
    "# print(feature_df.index)\n",
    "local_model = pyExp_obj['local_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          rule coefficient\n",
      "0  (intercept)     1.21719\n",
      "1  la <= 44.00    -2.10262\n",
      "2  la <= 76.00   -0.561556\n"
     ]
    }
   ],
   "source": [
    "print(local_model.explain( maxCoeffs=None))\n",
    "# print(local_model.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([(   'la', '<=',                 1.0),\n",
      "            (   'la', '<=',                 2.0),\n",
      "            (   'la', '<=',                 5.0),\n",
      "            (   'la', '<=',                 9.0),\n",
      "            (   'la', '<=',                17.0),\n",
      "            (   'la', '<=',                27.0),\n",
      "            (   'la', '<=',                44.0),\n",
      "            (   'la', '<=',                76.0),\n",
      "            (   'la', '<=',               163.0),\n",
      "            (   'ld', '<=',                 0.0),\n",
      "            ...\n",
      "            ('asawr', '<=',   0.433364602876798),\n",
      "            ('rsawr', '<=', 0.18055330452007923),\n",
      "            ('rsawr', '<=',  0.2564102564102564),\n",
      "            ('rsawr', '<=',  0.3196254791765793),\n",
      "            ('rsawr', '<=',  0.3754889178617992),\n",
      "            ('rsawr', '<=',  0.4287529047714299),\n",
      "            ('rsawr', '<=',  0.4816326530612245),\n",
      "            ('rsawr', '<=',  0.5758975125536251),\n",
      "            ('rsawr', '<=',  0.7078384798099763),\n",
      "            ('rsawr', '<=',  0.8487118531623176)],\n",
      "           names=['feature', 'operation', 'value'], length=165)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"9\" halign=\"left\">la</th>\n",
       "      <th>ld</th>\n",
       "      <th>...</th>\n",
       "      <th>asawr</th>\n",
       "      <th colspan=\"9\" halign=\"left\">rsawr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operation</th>\n",
       "      <th colspan=\"9\" halign=\"left\">&lt;=</th>\n",
       "      <th>&lt;=</th>\n",
       "      <th>...</th>\n",
       "      <th>&lt;=</th>\n",
       "      <th colspan=\"9\" halign=\"left\">&lt;=</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <th>1.000000</th>\n",
       "      <th>2.000000</th>\n",
       "      <th>5.000000</th>\n",
       "      <th>9.000000</th>\n",
       "      <th>17.000000</th>\n",
       "      <th>27.000000</th>\n",
       "      <th>44.000000</th>\n",
       "      <th>76.000000</th>\n",
       "      <th>163.000000</th>\n",
       "      <th>0.000000</th>\n",
       "      <th>...</th>\n",
       "      <th>0.433365</th>\n",
       "      <th>0.180553</th>\n",
       "      <th>0.256410</th>\n",
       "      <th>0.319625</th>\n",
       "      <th>0.375489</th>\n",
       "      <th>0.428753</th>\n",
       "      <th>0.481633</th>\n",
       "      <th>0.575898</th>\n",
       "      <th>0.707838</th>\n",
       "      <th>0.848712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2121 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature           la                                                         \\\n",
       "operation         <=                                                          \n",
       "value     1.000000   2.000000   5.000000   9.000000   17.000000  27.000000    \n",
       "0                  0          0          0          0          0          0   \n",
       "1                  0          0          0          0          0          0   \n",
       "2                  0          0          0          0          0          0   \n",
       "3                  0          0          0          0          0          0   \n",
       "4                  0          0          0          0          0          1   \n",
       "...              ...        ...        ...        ...        ...        ...   \n",
       "2116               1          1          1          1          1          1   \n",
       "2117               0          0          0          0          0          0   \n",
       "2118               0          0          0          0          0          0   \n",
       "2119               1          1          1          1          1          1   \n",
       "2120               0          0          0          0          0          0   \n",
       "\n",
       "feature                                            ld  ...      asawr  \\\n",
       "operation                                          <=  ...         <=   \n",
       "value     44.000000  76.000000  163.000000 0.000000    ... 0.433365     \n",
       "0                  0          0          0          0  ...          1   \n",
       "1                  0          0          0          1  ...          1   \n",
       "2                  0          0          0          0  ...          1   \n",
       "3                  0          0          0          0  ...          1   \n",
       "4                  1          1          1          0  ...          1   \n",
       "...              ...        ...        ...        ...  ...        ...   \n",
       "2116               1          1          1          0  ...          1   \n",
       "2117               0          0          1          0  ...          1   \n",
       "2118               1          1          1          1  ...          1   \n",
       "2119               1          1          1          0  ...          1   \n",
       "2120               0          0          0          0  ...          1   \n",
       "\n",
       "feature        rsawr                                                         \\\n",
       "operation         <=                                                          \n",
       "value     0.180553   0.256410   0.319625   0.375489   0.428753   0.481633     \n",
       "0                  0          0          0          0          0          0   \n",
       "1                  0          0          0          0          0          0   \n",
       "2                  0          0          0          0          0          0   \n",
       "3                  0          0          0          0          0          0   \n",
       "4                  0          0          0          0          0          0   \n",
       "...              ...        ...        ...        ...        ...        ...   \n",
       "2116               0          0          0          0          0          1   \n",
       "2117               1          1          1          1          1          1   \n",
       "2118               0          0          0          0          0          0   \n",
       "2119               0          0          0          0          0          0   \n",
       "2120               1          1          1          1          1          1   \n",
       "\n",
       "feature                                     \n",
       "operation                                   \n",
       "value     0.575898   0.707838   0.848712    \n",
       "0                  0          1          1  \n",
       "1                  0          1          1  \n",
       "2                  1          1          1  \n",
       "3                  0          1          1  \n",
       "4                  0          1          1  \n",
       "...              ...        ...        ...  \n",
       "2116               1          1          1  \n",
       "2117               1          1          1  \n",
       "2118               0          1          1  \n",
       "2119               0          0          1  \n",
       "2120               1          1          1  \n",
       "\n",
       "[2121 rows x 165 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_instance = pyExp_obj['synthetic_data']\n",
    "print(generated_instance.columns)\n",
    "display(generated_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature     la\n",
      "operation   <=\n",
      "value     44.0\n",
      "0            0\n",
      "1            0\n",
      "2            0\n",
      "3            0\n",
      "4            1\n",
      "...        ...\n",
      "2116         1\n",
      "2117         0\n",
      "2118         1\n",
      "2119         1\n",
      "2120         0\n",
      "\n",
      "[2121 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(generated_instance.loc[:, (generated_instance.columns.get_level_values(0)=='la') & \n",
    "                            (generated_instance.columns.get_level_values(1)=='<=') &\n",
    "                            (generated_instance.columns.get_level_values(2)==44.0)  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # search_function = 'crossoverinterpolation' # 'randompertubation' or 'crossoverinterpolation'\n",
    "# search_functions = ['randompertubation', 'crossoverinterpolation']\n",
    "\n",
    "# for i in range(0,len(feature_df)):\n",
    "#     X_explain = feature_df.iloc[[i]]\n",
    "#     y_explain = test_label.iloc[[i]]\n",
    "    \n",
    "#     row_index = str(X_explain.index[0])\n",
    "    \n",
    "#     try:\n",
    "#         pyExp_obj = pyExp.explain(X_explain,\n",
    "#                                    y_explain,\n",
    "#                                    search_function = search_function, \n",
    "#                                    top_k = 1000, \n",
    "#                                    max_rules=2000, \n",
    "#                                    max_iter =None, \n",
    "#                                    cv=5,\n",
    "#                                    debug = False)\n",
    "#         pickle.dump(pyExp_obj, open(pyExp_dir+search_function+'_'+row_index+'.pkl','wb'))\n",
    "        \n",
    "#         synt_pred = pyExp_obj['synthetic_predictions']\n",
    "#         print('{}: found {} defect from total {}'.format(row_index, str(np.sum(synt_pred)), \n",
    "#                                                          str(len(synt_pred))))\n",
    "# #         print('finished', row_index)\n",
    "#     except:\n",
    "#         problem_index.append(row_index)\n",
    "# #     print(row_index)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# explain_index = 13\n",
    "# X_explain = feature_df.iloc[[explain_index]]\n",
    "# X_explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# y_explain = test_label.iloc[[explain_index]]\n",
    "# y_explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# search_function = 'crossoverinterpolation' # 'randompertubation' or 'crossoverinterpolation''\n",
    "# start = time.time()\n",
    "# create_pyExp_rule_obj = pyExp.explain(X_explain,\n",
    "#                                y_explain,\n",
    "#                                search_function = search_function, \n",
    "#                                top_k = 1000, \n",
    "#                                max_rules=2000, \n",
    "#                                max_iter =None, \n",
    "#                                cv=5,\n",
    "#                                debug = False)\n",
    "\n",
    "# end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('time spent {}'.format(str(end-start)))\n",
    "# pickle.dump(create_pyExp_rule_obj, open(pyExp_dir+search_function+'_'+str(explain_index)+'.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(create_pyExp_rule_obj['synthetic_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(create_pyExp_rule_obj['synthetic_predictions'])\n",
    "# # print(np.sum(create_pyExp_rule_obj['synthetic_predictions']))\n",
    "# display(create_pyExp_rule_obj.keys())\n",
    "# print(create_pyExp_rule_obj['synthetic_predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_Oat",
   "language": "python",
   "name": "env_oat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
