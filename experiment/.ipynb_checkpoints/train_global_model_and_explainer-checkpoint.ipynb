{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os,  pickle, time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from my_util import *\n",
    "from lime.lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from pyexplainer.pyexplainer_pyexplainer import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data_path = './dataset/'\n",
    "result_dir = './eval_result/'\n",
    "dump_dataframe_dir = './prediction_result/'\n",
    "exp_dir = './explainer_object/'\n",
    "\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "    \n",
    "if not os.path.exists(dump_dataframe_dir):\n",
    "    os.makedirs(dump_dataframe_dir)\n",
    "    \n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_global_model(proj_name, x_train,y_train, global_model_name = 'RF'):\n",
    "    global_model_name = global_model_name.upper()\n",
    "    if global_model_name not in ['RF','LR']:\n",
    "        print('wrong global model name. the global model name must be RF or LR')\n",
    "        return\n",
    "    \n",
    "    smt = SMOTE(k_neighbors=5, random_state=42, n_jobs=24)\n",
    "    new_x_train, new_y_train = smt.fit_resample(x_train, y_train)\n",
    "    \n",
    "    if global_model_name == 'RF':\n",
    "        global_model = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=24)\n",
    "    elif global_model_name == 'LR':\n",
    "        global_model = LogisticRegression(random_state=0, n_jobs=24)\n",
    "        \n",
    "    global_model.fit(new_x_train, new_y_train)\n",
    "    pickle.dump(global_model, open(proj_name+'_'+global_model_name+'_global_model.pkl','wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correctly_predicted_defective_commit_indices(proj_name, global_model_name, x_test, y_test):\n",
    "    global_model_name = global_model_name.upper()\n",
    "    if global_model_name not in ['RF','LR']:\n",
    "        print('wrong global model name. the global model name must be RF or LR')\n",
    "        return\n",
    "    \n",
    "    prediction_df_dir = dump_dataframe_dir+proj_name+'_'+global_model_name+'_prediction_result.csv'\n",
    "    correctly_predict_df_dir = dump_dataframe_dir+proj_name+'_'+global_model_name+'_correctly_predict_as_defective.csv'\n",
    "    \n",
    "    if not os.path.exists(prediction_df_dir) or not os.path.exists(correctly_predict_df_dir):\n",
    "        global_model = pickle.load(open(proj_name+'_'+global_model_name+'_global_model.pkl','rb'))\n",
    "\n",
    "        pred = global_model.predict(x_test)\n",
    "        defective_prob = global_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "        prediction_df = x_test.copy()\n",
    "        prediction_df['pred'] = pred\n",
    "        prediction_df['defective_prob'] = defective_prob\n",
    "        prediction_df['defect'] = y_test\n",
    "\n",
    "        correctly_predict_df = prediction_df[(prediction_df['pred']==1) & (prediction_df['defect']==1)]\n",
    "\n",
    "\n",
    "        prediction_df.to_csv(prediction_df_dir)\n",
    "        correctly_predict_df.to_csv(correctly_predict_df_dir)\n",
    "    \n",
    "    else:\n",
    "        prediction_df = pd.read_csv(prediction_df_dir)\n",
    "        correctly_predict_df = pd.read_csv(correctly_predict_df_dir)\n",
    "        \n",
    "        prediction_df = prediction_df.set_index('commit_id')\n",
    "        correctly_predict_df = correctly_predict_df.set_index('commit_id')\n",
    "        \n",
    "    return correctly_predict_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def create_explainer(proj_name, global_model_name, x_train, x_test, y_train, y_test, df_indices):\n",
    "    \n",
    "    global_model_name = global_model_name.upper()\n",
    "    if global_model_name not in ['RF','LR']:\n",
    "        print('wrong global model name. the global model name must be RF or LR')\n",
    "        return\n",
    "    \n",
    "    global_model = pickle.load(open(proj_name+'_'+global_model_name+'_global_model.pkl','rb'))\n",
    "\n",
    "    indep = x_test.columns\n",
    "    dep = 'defect'\n",
    "    class_label = ['clean', 'defect']\n",
    "    \n",
    "    # for our apporach\n",
    "    pyExp = PyExplainer(x_train, y_train, indep, dep, global_model, class_label)\n",
    "\n",
    "    # for baseline\n",
    "    # note: 6 is index of 'self' feature\n",
    "    lime_explainer = LimeTabularExplainer(x_train.values, categorical_features=[6],\n",
    "                                      feature_names=indep, class_names=class_label, \n",
    "                                      random_state=0)\n",
    "\n",
    "    feature_df = x_test.loc[df_indices]\n",
    "    test_label = y_test.loc[df_indices]\n",
    "    \n",
    "    for i in range(0,len(feature_df)):\n",
    "        X_explain = feature_df.iloc[[i]]\n",
    "        y_explain = test_label.iloc[[i]]\n",
    "\n",
    "        row_index = str(X_explain.index[0])\n",
    "\n",
    "        pyExp_obj = pyExp.explain(X_explain,\n",
    "                                   y_explain,\n",
    "                                   search_function = 'CrossoverInterpolation')\n",
    "        \n",
    "        pyExp_obj['commit_id'] = row_index\n",
    "\n",
    "        # because I don't want to change key name in another evaluation file\n",
    "        pyExp_obj['local_model'] = pyExp_obj['local_rulefit_model']\n",
    "        del pyExp_obj['local_rulefit_model']\n",
    "        \n",
    "        X_explain = feature_df.iloc[i] # to prevent error in LIME\n",
    "        \n",
    "        exp, synt_inst, synt_inst_for_local_model, selected_feature_indices, local_model = lime_explainer.explain_instance(X_explain, \n",
    "                                                                                                                           global_model.predict_proba, \n",
    "                                                                                                                           num_samples=5000)\n",
    "        lime_obj = {}\n",
    "        lime_obj['rule'] = exp\n",
    "        lime_obj['synthetic_instance_for_global_model'] = synt_inst\n",
    "        lime_obj['synthetic_instance_for_lobal_model'] = synt_inst_for_local_model\n",
    "        lime_obj['local_model'] = local_model\n",
    "        lime_obj['selected_feature_indeces'] = selected_feature_indices\n",
    "        lime_obj['commit_id'] = row_index\n",
    "\n",
    "        all_explainer = {'pyExplainer':pyExp_obj, 'LIME': lime_obj}\n",
    "        pickle.dump(all_explainer, open(exp_dir+proj_name+'_'+global_model_name+'_all_explainer_'+row_index+'.pkl','wb'))\n",
    "        \n",
    "        print('finished',row_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_global_model_runner(proj_name):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = prepare_data(proj_name, mode = 'all')\n",
    "\n",
    "    train_global_model(proj_name, x_train, y_train,'RF')\n",
    "    print('train RF of {} finished'.format(proj_name))\n",
    "    train_global_model(proj_name, x_train, y_train,'LR')\n",
    "    print('train LR of {} finished'.format(proj_name))\n",
    "    \n",
    "def train_explainer(proj_name):\n",
    "    x_train, x_test, y_train, y_test = prepare_data(proj_name, mode = 'all')\n",
    "\n",
    "    rf_correctly_predict_indice = get_correctly_predicted_defective_commit_indices(proj_name, 'rf', x_test, y_test)\n",
    "    lr_correctly_predict_indice = get_correctly_predicted_defective_commit_indices(proj_name, 'lr', x_test, y_test)\n",
    "\n",
    "    rf_correctly_predict_indice = set(rf_correctly_predict_indice)\n",
    "\n",
    "    lr_correctly_predict_indice = set(lr_correctly_predict_indice)\n",
    "\n",
    "    create_every_explainer(proj_name, 'RF', x_train, x_test, y_train, y_test, rf_correctly_predict_indice)\n",
    "    create_every_explainer(proj_name, 'LR', x_train, x_test, y_train, y_test, lr_correctly_predict_indice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_Oat",
   "language": "python",
   "name": "env_oat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
